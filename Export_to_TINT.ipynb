{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2206d62",
   "metadata": {},
   "source": [
    "# Convert recording and sorting extractor data to TINT format\n",
    "\n",
    "The Hussaini lab uses the proprietary TINT software from Axona to analyze extracellular electrophysiology data. While we are already able to read various data formats from Axona (`raw` data or `unit` data) into spikeinterface, perform preprocessing, spike sorting and export the data to NWB, we also want to allow to export data to the TINT format. \n",
    "\n",
    "The TINT format is essentially the same as the `unit` data, including `.X` and `.pos` files, but also `.cut` or `.clu`. The latter two contain information about the spike sorted units.\n",
    "\n",
    "The conversion can be facilitated by using the existing tools from the Hussaini lab, which [convert `.bin` data to `.X` and `.pos`](https://github.com/HussainiLab/BinConverter/blob/master/BinConverter/core/ConversionFunctions.py). Some of this code is only relevant for using the GUI, which did not work for me. I cleared out GUI code and ran a conversion from `.bin` to `.X` and `.pos` in this notebook: [explore_hussaini_tools.ipynb](https://github.com/sbuergers/hussaini-lab-to-nwb-notebooks/blob/master/explore_hussaini_tools.ipynb).\n",
    "\n",
    "They also already wrote a [`write_cut()`](https://github.com/GeoffBarrett/gebaSpike/blob/967097ec28592182ef9783d2d391930e1c63ca58/gebaSpike/core/writeCut.py) function.\n",
    "\n",
    "We can test our solutions by reading data with these [Hussaini lab tools](https://github.com/HussainiLab/BinConverter/blob/master/BinConverter/core/Tint_Matlab.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f2c870",
   "metadata": {},
   "source": [
    "<a id='index'></a>\n",
    "## Index\n",
    "\n",
    "* [Testing functions](#testing_functions)\n",
    "* [Hussaini-lab functions](#hussaini-lab_functions)\n",
    "* [Convert Recording Extractor to TINT](#Convert_recording_extractor_to_tint)\n",
    "* [Convert Sorting Extractor to TINT](#Convert_sorting_extractor_to_tint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23c3f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0] linux /home/sbuergers/spikeinterface/spikeinterface_new_api/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 8)\n",
    "plt.rcParams.update({'font.size':14})\n",
    "%matplotlib inline\n",
    "\n",
    "import spikeextractors as se\n",
    "\n",
    "print(sys.version, sys.platform, sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5598a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory =  /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint_no_bin\n",
      "Output directory =  /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint_no_bin/conversion_to_tint\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "\n",
    "dir_name = Path('/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint_no_bin')\n",
    "print('Input directory = ', dir_name)\n",
    "\n",
    "save_dir = dir_name / 'conversion_to_tint'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "print('Output directory = ', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba1ca4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cached spikeextractors data\n",
    "\n",
    "r_cache = se.load_extractor_from_pickle(os.path.join(dir_name, 'cached_unit_data_no_bin_preproc.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27ae421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbuergers/spikeinterface/spikeinterface_new_api/venv/lib/python3.8/site-packages/hdmf/common/table.py:442: UserWarning: An attribute 'name' already exists on DynamicTable 'electrodes' so this column cannot be accessed as an attribute, e.g., table.name; it can only be accessed using other methods, e.g., table['name'].\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Read NWB recording data\n",
    "\n",
    "nwb_dir = Path(dir_name, 'nwb')\n",
    "recording_nwb = se.NwbRecordingExtractor(nwb_dir / 'axona_tutorial_re2.nwb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23179f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read NWB sorting data\n",
    "\n",
    "sorting_nwb = se.NwbSortingExtractor(nwb_dir / 'axona_se_MS4.nwb', sampling_frequency=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8adadf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spikeextractors.extractors.bindatrecordingextractor.bindatrecordingextractor.BinDatRecordingExtractor'>\n",
      "<class 'spikeextractors.extractors.nwbextractors.nwbextractors.NwbRecordingExtractor'>\n",
      "<class 'spikeextractors.extractors.nwbextractors.nwbextractors.NwbSortingExtractor'>\n"
     ]
    }
   ],
   "source": [
    "# Show data types of different objects\n",
    "\n",
    "print(type(r_cache))\n",
    "print(type(recording_nwb))\n",
    "print(type(sorting_nwb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516edbc4",
   "metadata": {},
   "source": [
    "<a id=\"testing_functions\"></a>\n",
    "## Testing functions\n",
    "[back to index](#index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d435e60",
   "metadata": {},
   "source": [
    "As we start exporting to putative TINT format, we will want to check if we can read it back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "771a4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeextractors.extractors.axonaunitrecordingextractor import AxonaUnitRecordingExtractor\n",
    "import os\n",
    "\n",
    "\n",
    "def test_axonaunitrecordingextractor(filename):\n",
    "    '''Reads UNIT data with AxonaUnitRecordingExtractor and\n",
    "    performs some simple operations as a sanity check. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str or Path\n",
    "        Full filename of `.set` file (could be any extension actually)\n",
    "    '''\n",
    "    re = AxonaUnitRecordingExtractor(filename=filename)\n",
    "    \n",
    "    # TEST AXONARECORDINGEXTRACTOR\n",
    "    # Retrieve some simple recording information and print it\n",
    "    recording = re\n",
    "    print('Channel ids = {}'.format(recording.get_channel_ids()))\n",
    "    print('Num. channels = {}'.format(len(recording.get_channel_ids())))\n",
    "    print('Sampling frequency = {} Hz'.format(recording.get_sampling_frequency()))\n",
    "    print('Num. timepoints = {}'.format(recording.get_num_frames()))\n",
    "    print('Stdev. on third channel = {}'.format(np.std(recording.get_traces(channel_ids=2))))\n",
    "    print('Location of third electrode = {}'.format(\n",
    "        recording.get_channel_property(channel_id=2, property_name='location')))\n",
    "    print('Channel groups = {}'.format(recording.get_channel_groups()))\n",
    "    \n",
    "    # TEST NEO_READER (axonaio)\n",
    "    print(recording.neo_reader.header['signal_channels'])\n",
    "    \n",
    "    \n",
    "def test_tetrode_files(filename):\n",
    "    '''Reads UNIT data with AxonaUnitRecordingExtractor and\n",
    "    performs some simple operations as a sanity check. \n",
    "    Will only test .X  and .set files (no .clu or .cut, no .pos).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str or Path\n",
    "        Full filename of `.set` file (could be any extension actually)\n",
    "    '''\n",
    "    test_axonaunitrecordingextractor(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f83ea",
   "metadata": {},
   "source": [
    "<a id=\"hussaini-lab_functions\"></a>\n",
    "## Hussaini-lab functions\n",
    "[back to index](#index)\n",
    "\n",
    "`gebaSpike` actually wants already existing `.cut` or `.clu` files, and allows modifying them. So these might not be all that useful for exporting to `.cut` or `.clu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2464e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From \n",
    "# https://github.com/GeoffBarrett/gebaSpike/blob/967097ec28592182ef9783d2d391930e1c63ca58/gebaSpike/main.py\n",
    "\n",
    "def save_function(self):\n",
    "    \"\"\"\n",
    "    this method will save the .cut file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if self.cut_filename.text() == default_filename:\n",
    "        return\n",
    "\n",
    "    save_filename = os.path.realpath(self.cut_filename.text())\n",
    "\n",
    "    if os.path.exists(save_filename):\n",
    "        self.choice = None\n",
    "        self.LogError.signal.emit('OverwriteCut!%s' % save_filename)\n",
    "        while self.choice is None:\n",
    "            time.sleep(0.1)\n",
    "\n",
    "        if self.choice != QtWidgets.QMessageBox.Yes:\n",
    "            return\n",
    "\n",
    "    if len(self.tetrode_data) == 0:\n",
    "        return\n",
    "\n",
    "    # organize the cut data\n",
    "    n_spikes_expected = self.tetrode_data.shape[1]\n",
    "    n_spikes = len(np.asarray([item for sublist in self.cell_indices.values() for item in sublist]))\n",
    "\n",
    "    # check that with the manipulation of the spikes, that we still have the correct number of spikes\n",
    "    if n_spikes != n_spikes_expected:\n",
    "        self.choice = None\n",
    "        self.LogError.signal.emit('cutSizeError')\n",
    "        while self.choice is None:\n",
    "            time.sleep(0.1)\n",
    "        return\n",
    "\n",
    "    # we will check if we are missing some of the spikes somehow. If we kept track of them, then the indices from\n",
    "    # the spikes, when sorted, should produce an array from 0 -> N-1 spikes.\n",
    "    if not np.array_equal(np.sort(np.asarray([item for sublist in self.cell_indices.values() for item in sublist])),\n",
    "                      np.arange(len(self.cut_data_original))):\n",
    "        self.choice = None\n",
    "        self.LogError.signal.emit('cutIndexError')\n",
    "        while self.choice is None:\n",
    "            time.sleep(0.1)\n",
    "        return\n",
    "\n",
    "    cut_values = np.zeros(n_spikes)\n",
    "    for cell, cell_indices in self.cell_indices.items():\n",
    "        cut_values[cell_indices] = cell\n",
    "\n",
    "    if '.clu.' in save_filename:\n",
    "        # save the .clu filename\n",
    "        write_clu(save_filename, cut_values)\n",
    "        self.choice = None\n",
    "        self.LogError.signal.emit('saveCompleteClu')\n",
    "        while self.choice is None:\n",
    "            time.sleep(0.1)\n",
    "        self.actions_made = False\n",
    "\n",
    "    else:\n",
    "        # save the cut filename\n",
    "        write_cut(save_filename, cut_values)\n",
    "        self.choice = None\n",
    "        self.LogError.signal.emit('saveComplete')\n",
    "        while self.choice is None:\n",
    "            time.sleep(0.1)\n",
    "        self.actions_made = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "764421ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From \n",
    "# https://github.com/GeoffBarrett/gebaSpike/blob/967097ec28592182ef9783d2d391930e1c63ca58/gebaSpike/core/writeCut.py\n",
    "\n",
    "def write_cut(cut_filename, cut, basename=None):\n",
    "    if basename is None:\n",
    "        basename = os.path.basename(os.path.splitext(cut_filename)[0])\n",
    "\n",
    "    unique_cells = np.unique(cut)\n",
    "\n",
    "    if 0 not in unique_cells:\n",
    "        # if it happens that there is no zero cell, add it anyways\n",
    "        unique_cells = np.insert(unique_cells, 0, 0)  # object, index, value to insert\n",
    "\n",
    "    n_clusters = len(np.unique(cut))\n",
    "    n_spikes = len(cut)\n",
    "\n",
    "    write_list = []  # the list of values to write\n",
    "\n",
    "    tab = '    '  # the spaces didn't line up with my tab so I just created a string with enough spaces\n",
    "    empty_space = '               '  # some of the empty spaces don't line up to x tabs\n",
    "\n",
    "    # we add 1 to n_clusters because zero is the garbage cell that no one uses\n",
    "    write_list.append('n_clusters: %d\\n' % (n_clusters))\n",
    "    write_list.append('n_channels: 4\\n')\n",
    "    write_list.append('n_params: 2\\n')\n",
    "    write_list.append('times_used_in_Vt:%s' % ((tab + '0') * 4 + '\\n'))\n",
    "\n",
    "    zero_string = (tab + '0') * 8 + '\\n'\n",
    "\n",
    "    for cell_i in np.arange(n_clusters):\n",
    "        write_list.append(' cluster: %d center:%s' % (cell_i, zero_string))\n",
    "        write_list.append('%smin:%s' % (empty_space, zero_string))\n",
    "        write_list.append('%smax:%s' % (empty_space, zero_string))\n",
    "    write_list.append('\\nExact_cut_for: %s spikes: %d\\n' % (basename, n_spikes))\n",
    "\n",
    "    # now the cut file lists 25 values per row\n",
    "    n_rows = int(np.floor(n_spikes / 25))  # number of full rows\n",
    "\n",
    "    remaining = int(n_spikes - n_rows * 25)\n",
    "    cut_string = ('%3u' * 25 + '\\n') * n_rows + '%3u' * remaining\n",
    "\n",
    "    write_list.append(cut_string % (tuple(cut)))\n",
    "\n",
    "    with open(cut_filename, 'w') as f:\n",
    "        f.writelines(write_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "373b1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From \n",
    "# https://github.com/GeoffBarrett/gebaSpike/blob/967097ec28592182ef9783d2d391930e1c63ca58/gebaSpike/core/writeCut.py\n",
    "\n",
    "def write_clu(clu_filename, data):\n",
    "    # the .clu files and the .cut files are different since the .clu files are the .cut files (with no manual sorting)\n",
    "    # without the headers, and the values go from 1 -> N instead of 0 -> N, (1-based numbering instead of 0-based). Thus\n",
    "    # we add 1 to the .cut data to get the .clu data\n",
    "\n",
    "    data = np.asarray(data).astype(int)  # ensuring that the data is the integer data-type\n",
    "\n",
    "    data += 1  # making the data 1-based instead of 0-based\n",
    "\n",
    "    # calculating the number of clusters\n",
    "    n_clust = len(np.unique(data))\n",
    "\n",
    "    # ensuring that the cluster number is the 1st value\n",
    "    data = np.concatenate(([n_clust], data))\n",
    "\n",
    "    # saving the data as a column (delimter='\\n') and integer format.\n",
    "    np.savetxt(clu_filename, data, fmt='%d', delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9382b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c7390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723573a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0daa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-c3382ba5b84d>:309: DeprecationWarning: GraphicsWindow is deprecated, use GraphicsLayoutWidget instead,will be removed in 0.13\n",
      "  self.feature_win = pg.GraphicsWindow()\n",
      "<ipython-input-57-c3382ba5b84d>:320: DeprecationWarning: GraphicsWindow is deprecated, use GraphicsLayoutWidget instead,will be removed in 0.13\n",
      "  self.unit_win = pg.GraphicsWindow()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pyqtgraph as pg\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from pyqtgraph.widgets.MatplotlibWidget import MatplotlibWidget\n",
    "from gebaSpike.core.gui_utils import validate_session, Communicate, validate_cut, find_tetrodes\n",
    "from gebaSpike.core.default_parameters import project_name, default_filename, defaultXAxis, defaultYAxis, defaultZAxis, openGL, \\\n",
    "    default_move_channel, max_spike_plots, alt_action_button\n",
    "# from core.Tint_Matlab import find_tetrodes\n",
    "from gebaSpike.core.plot_functions import plot_session, cut_cell, get_index_from_roi\n",
    "from gebaSpike.core.waveform_cut_functions import moveToChannel, maxSpikesChange\n",
    "from gebaSpike.core.undo import undo_function\n",
    "from gebaSpike.core.feature_plot import feature_name_map\n",
    "from gebaSpike.core.PopUpCutting import PopUpCutWindow\n",
    "from gebaSpike.core.writeCut import write_cut, write_clu\n",
    "import pyqtgraph.opengl as gl\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "version = \"1.1.0\"\n",
    "\n",
    "\n",
    "class gebaSpikeObj():\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        initializes many of the variables\n",
    "        \"\"\"\n",
    "\n",
    "        # initializing attributes\n",
    "        self.plotted_tetrode = None\n",
    "        self.change_set_with_tetrode = True\n",
    "        self.multiple_files = False\n",
    "        self.cut_filename = None\n",
    "        self.choose_cut_filename_btn = None\n",
    "        self.feature_win = None\n",
    "        self.quit_btn = None\n",
    "        self.filename = None\n",
    "        self.choose_filename_btn = None\n",
    "        self.x_axis_cb = None\n",
    "        self.y_axis_cb = None\n",
    "        self.z_axis_cb = None\n",
    "        self.tetrode_cb = None\n",
    "        self.choice = None  # the current choice for the error popups\n",
    "        self.plot_btn = None\n",
    "        self.feature_plot = None\n",
    "\n",
    "        # initialize list of actions to undo\n",
    "        self.latest_actions = {}\n",
    "\n",
    "        # bool for if an action has been made, I suppose we could take the length of the actions attribute\n",
    "        self.actions_made = False\n",
    "\n",
    "        # bool representing if the user is dragging the mouse (for drawing the line segments on the graphs)\n",
    "        self.drag_active = False\n",
    "\n",
    "        # the graph index that was last dragged upon with the mouse\n",
    "        self.last_drag_index = None\n",
    "\n",
    "        self.feature_data = None\n",
    "        self.tetrode_data = None\n",
    "        self.tetrode_data_loaded = False\n",
    "        self.cut_data = None\n",
    "        self.cut_data_loaded = False\n",
    "        self.cut_data_original = None\n",
    "        self.spike_times = None\n",
    "        self.scatterItem = None\n",
    "        self.glViewWidget = None\n",
    "        self.feature_plot_added = False\n",
    "        self.samples_per_spike = None\n",
    "\n",
    "        # keep a list of the positions that the cells are plotted in\n",
    "        self.unit_positions = {}\n",
    "\n",
    "        # not all the spikes are plotted at once, so we will keep a dict of which subsample is plotted\n",
    "        self.cell_subsample_i = {}\n",
    "\n",
    "        self.unit_drag_lines = {}\n",
    "        self.active_ROI = []\n",
    "        self.unit_data = {}\n",
    "\n",
    "        self.xline = None\n",
    "        self.yline = None\n",
    "        self.zline = None\n",
    "\n",
    "        self.max_spike_plots = None\n",
    "\n",
    "        self.n_channels = None\n",
    "\n",
    "        self.invalid_channel = None\n",
    "\n",
    "        self.cell_indices = {}\n",
    "\n",
    "        self.spike_colors = None\n",
    "\n",
    "        self.original_cell_count = {}\n",
    "\n",
    "        self.unit_plots = {}\n",
    "        self.vb = {}\n",
    "        self.plot_lines = {}\n",
    "        self.avg_plot_lines = {}\n",
    "        self.unit_rows = 0\n",
    "        self.unit_cols = 0\n",
    "\n",
    "    def save_function(self):\n",
    "        \"\"\"\n",
    "        this method will save the .cut file\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        save_filename = os.path.realpath(self.cut_filename.text())\n",
    "\n",
    "        # organize the cut data\n",
    "        n_spikes_expected = self.tetrode_data.shape[1]\n",
    "        n_spikes = len(np.asarray([item for sublist in self.cell_indices.values() for item in sublist]))\n",
    "\n",
    "        # check that with the manipulation of the spikes, that we still have the correct number of spikes\n",
    "        if n_spikes != n_spikes_expected:\n",
    "            self.choice = None\n",
    "            self.LogError.signal.emit('cutSizeError')\n",
    "            while self.choice is None:\n",
    "                time.sleep(0.1)\n",
    "            return\n",
    "\n",
    "        # we will check if we are missing some of the spikes somehow. If we kept track of them, then the indices from\n",
    "        # the spikes, when sorted, should produce an array from 0 -> N-1 spikes.\n",
    "        if not np.array_equal(np.sort(np.asarray([item for sublist in self.cell_indices.values() for item in sublist])),\n",
    "                          np.arange(len(self.cut_data_original))):\n",
    "            self.choice = None\n",
    "            self.LogError.signal.emit('cutIndexError')\n",
    "            while self.choice is None:\n",
    "                time.sleep(0.1)\n",
    "            return\n",
    "\n",
    "        cut_values = np.zeros(n_spikes)\n",
    "        for cell, cell_indices in self.cell_indices.items():\n",
    "            cut_values[cell_indices] = cell\n",
    "\n",
    "        if '.clu.' in save_filename:\n",
    "            # save the .clu filename\n",
    "            write_clu(save_filename, cut_values)\n",
    "            self.choice = None\n",
    "            self.LogError.signal.emit('saveCompleteClu')\n",
    "            while self.choice is None:\n",
    "                time.sleep(0.1)\n",
    "            self.actions_made = False\n",
    "\n",
    "        else:\n",
    "            # save the cut filename\n",
    "            write_cut(save_filename, cut_values)\n",
    "            self.choice = None\n",
    "            self.LogError.signal.emit('saveComplete')\n",
    "            while self.choice is None:\n",
    "                time.sleep(0.1)\n",
    "            self.actions_made = False\n",
    "\n",
    "    def set_cut_filename(self):\n",
    "        \"\"\"\n",
    "        When you choose a session filename, it will trigger this function which will automatically set the .cut\n",
    "        filename for the user.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.multiple_files:\n",
    "            filename = self.filename.text()\n",
    "\n",
    "            try:\n",
    "                tetrode = int(self.tetrode_cb.currentText())\n",
    "            except ValueError:\n",
    "                return\n",
    "\n",
    "            cut_filename = '%s_%d.cut' % (\n",
    "                os.path.splitext(filename)[0], tetrode)\n",
    "            clu_filename = '%s.clu.%d' % (\n",
    "                os.path.splitext(filename)[0], tetrode)\n",
    "            if os.path.exists(cut_filename):\n",
    "                self.cut_filename.setText(os.path.realpath(cut_filename))\n",
    "            elif os.path.exists(clu_filename):\n",
    "                self.cut_filename.setText(os.path.realpath(clu_filename))\n",
    "\n",
    "    def tetrode_changed(self):\n",
    "        \"\"\"\n",
    "        Upon changing of the tetrode drop-menu, the .cut file will also need to be changed (trigger that change)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # we will update the cut_filename\n",
    "        if self.change_set_with_tetrode:\n",
    "            self.set_cut_filename()\n",
    "            # self.reset_parameters()\n",
    "\n",
    "    def filename_changed(self):\n",
    "        \"\"\"\n",
    "        This method will run when the filename LineEdit has been changed.\n",
    "        It will essentially find the active tetrodes and populate the drop-down menu.\n",
    "        \"\"\"\n",
    "\n",
    "        filename = self.filename.text()\n",
    "\n",
    "        if self.multiple_files:\n",
    "            filename = filename.split(', ')\n",
    "\n",
    "        else:\n",
    "            filename = [filename]\n",
    "\n",
    "        # ensure that the files exist\n",
    "        for file in filename:\n",
    "            if not os.path.exists(file):\n",
    "                return\n",
    "\n",
    "        tetrodes = []\n",
    "\n",
    "        self.tetrode_cb.clear()\n",
    "\n",
    "        tetrode_list = find_tetrodes(self, self.filename.text())\n",
    "\n",
    "        # get the extension value (excluding the .) so we can create a list of tetrode integers\n",
    "\n",
    "        for file in tetrode_list:\n",
    "            tetrode = os.path.splitext(file)[-1][1:]\n",
    "            tetrodes.append(tetrode)\n",
    "\n",
    "        # make a list of added tetrodes\n",
    "        added_tetrodes = []\n",
    "        for tetrode in sorted(tetrodes):\n",
    "            # check if the tetrode value has been added already\n",
    "            if tetrode in added_tetrodes:\n",
    "                # continue if already added\n",
    "                continue\n",
    "\n",
    "            # add the item to the list containing the tetrode value\n",
    "            self.tetrode_cb.addItem(tetrode)\n",
    "\n",
    "            # add the tetrode value to the added_tetrodes list\n",
    "            added_tetrodes.append(tetrode)\n",
    "\n",
    "        # set the cut_filename\n",
    "        self.set_cut_filename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1a7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2491d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ab3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df885a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gebaSpike.core.Tint_Matlab import is_tetrode, read_clu\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def find_tetrodes(set_fullpath):\n",
    "    \"\"\"finds the tetrode files available for a given .set file if there is a  .cut file existing.\n",
    "    if multiple set files were provided, then we will find the tetrode values that overlap for the both of them.\"\"\"\n",
    "\n",
    "    set_files = [set_fullpath]\n",
    "\n",
    "    num_files = len(set_files)\n",
    "\n",
    "    tetrode_files = {}\n",
    "\n",
    "    # finds all the tetrode files\n",
    "    for file in set_files:\n",
    "        tetrode_path, session = os.path.split(file)\n",
    "        session, _ = os.path.splitext(session)\n",
    "\n",
    "        # getting all the files in that directory\n",
    "        file_list = os.listdir(tetrode_path)\n",
    "\n",
    "        # acquiring only a list of tetrodes that belong to that set file\n",
    "        tetrode_list = [os.path.join(tetrode_path, file) for file in file_list\n",
    "                        if is_tetrode(file, session)]\n",
    "\n",
    "        # if the .cut or .clu.X file doesn't exist remove from list\n",
    "        tetrode_list = [file for file in tetrode_list if (\n",
    "            os.path.exists(\n",
    "                os.path.join(tetrode_path, '%s_%s.cut' % (\n",
    "                    os.path.splitext(file)[0], os.path.splitext(file)[1][1:]))) or\n",
    "            os.path.exists(\n",
    "                os.path.join(tetrode_path, '%s.clu.%s' % (\n",
    "                    os.path.splitext(file)[0], os.path.splitext(file)[1][1:])))\n",
    "        )]\n",
    "\n",
    "        tetrode_files[file] = tetrode_list\n",
    "\n",
    "    # count the files to ensure that we have the same amount of tetrode files as we do sessions\n",
    "\n",
    "    tetrode_count = Counter()\n",
    "    for tet_files in tetrode_files.values():\n",
    "        for file in tet_files:\n",
    "            ext = os.path.splitext(file)[-1]\n",
    "\n",
    "            if ext in tetrode_count:\n",
    "                tetrode_count[ext] += 1\n",
    "            else:\n",
    "                tetrode_count[ext] = 1\n",
    "\n",
    "    # we will only include the tetrodes that are existing across all sessions provided\n",
    "    tetrode_list = []\n",
    "    for ext in sorted(tetrode_count):\n",
    "        if tetrode_count[ext] == num_files:\n",
    "            # this could likely be optimized, but I figure it won't take too long to iterate through these files anyways\n",
    "            for values in tetrode_files.values():\n",
    "                ext_files = [file for file in values if os.path.splitext(file)[-1] == ext]\n",
    "                tetrode_list.extend(ext_files)\n",
    "\n",
    "    return tetrode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6e54cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_fullpath = Path('/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Axona_Tint_1ms/20201004_Tint.set')\n",
    "\n",
    "tetrode_list = find_tetrodes(set_fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c34bb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Axona_Tint_1ms/20201004_Tint.1',\n",
       " '/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Axona_Tint_1ms/20201004_Tint.2',\n",
       " '/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Axona_Tint_1ms/20201004_Tint.3',\n",
       " '/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Axona_Tint_1ms/20201004_Tint.4']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tetrode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d1a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124c443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f191b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09da35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d7be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b8a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95e38e19",
   "metadata": {},
   "source": [
    "<a id=\"Convert_recording_extractor_to_tint\"></a>\n",
    "## Convert Recording extractor to TINT\n",
    "[back to index](#index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e23771",
   "metadata": {},
   "source": [
    "Hmm, since we are writing to TINT, thereby creating `.X` tetrode files, we throw away all information in-between spikes. There is no point to convert the fake continuous recording used for spike sorting to TINT at all. We really only want to export the spike sorting output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anything to do here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd0983",
   "metadata": {},
   "source": [
    "<a id=\"Convert_sorting_extractor_to_tint\"></a>\n",
    "## Convert Sorting extractor to TINT\n",
    "[back to index](#index)\n",
    "\n",
    "There are several points in the pipeline at which we might want to export to TINT. Ideally it should work for any `SortingExtractor` object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "060314fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where do we load data from?\n",
      "\n",
      " /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint_no_bin\n"
     ]
    }
   ],
   "source": [
    "print('Where do we load data from?\\n\\n', dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485c41e",
   "metadata": {},
   "source": [
    "From a sorting extractor we can obtain a list unit spike sample arrays. We can convert this to the .clu or .cut type array of unit ID labels for each spike.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d543a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_spike_train_to_label_array(spike_train):\n",
    "    '''Takes a list of arrays, where each array is a series of\n",
    "    sample points at which a spike occured for a given unit\n",
    "    (each list item is a unit). Converts to .cut array, i.e.\n",
    "    orders spike samples from all units and labels each sample\n",
    "    with the appropriate unit ID.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_train : List of np.arrays\n",
    "        Output of `get_units_spike_train()` method of sorting extractor\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    unit_labels_sorted : np.array\n",
    "        Each entry is the unit ID corresponding to the spike sample that\n",
    "        occured at this ordinal position\n",
    "    '''\n",
    "\n",
    "    # Generate Index array (indexing the unit for a given spike sample)\n",
    "    unit_labels = []\n",
    "    for i, l in enumerate(spike_train):\n",
    "        unit_labels.append(np.ones((len(l),), dtype=int) * i)\n",
    "    \n",
    "    # Flatten lists and sort them\n",
    "    spike_train_flat = np.concatenate(spike_train).ravel()\n",
    "    unit_labels_flat = np.concatenate(unit_labels).ravel()\n",
    "\n",
    "    sort_index = np.argsort(spike_train_flat)\n",
    "\n",
    "    unit_labels_sorted = unit_labels_flat[sort_index]\n",
    "\n",
    "    return unit_labels_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e4897854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201004_Tint_1\n"
     ]
    }
   ],
   "source": [
    "cut_filename = Path('/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Axona_Tint_1ms/20201004_Tint_1.cut')\n",
    "\n",
    "basename = os.path.basename(os.path.splitext(cut_filename)[0])\n",
    "\n",
    "print(basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68bd526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_cut_file(cut_filename, unit_labels):\n",
    "    '''Write spike sorting output to .cut file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cut_filename : str or Path\n",
    "        Full filename of .cut file to write to. A given .cut file belongs\n",
    "        to a given tetrode file. For example, for tetrode `my_file.1`, the\n",
    "        corresponding cut_filename should be `my_file_1.cut`.\n",
    "    unit_labels : np.array\n",
    "        Vector of unit labels for each spike sample (ordered by time of \n",
    "        occurence)\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    # Given a sortingextractor called sorting_nwb:\n",
    "    spike_train = sorting_nwb.get_units_spike_train()\n",
    "    unit_labels = convert_spike_train_to_label_array(spike_train)\n",
    "    write_to_cut_file(cut_filename, unit_labels)\n",
    "    \n",
    "    ---\n",
    "    Largely based on gebaSpike implementation by Geoff Barrett\n",
    "    https://github.com/GeoffBarrett/gebaSpike\n",
    "    '''\n",
    "\n",
    "    unique_cells = np.unique(unit_labels)\n",
    "\n",
    "    n_clusters = len(np.unique(unit_labels))\n",
    "    n_spikes = len(unit_labels)\n",
    "\n",
    "    write_list = []\n",
    "\n",
    "    tab = '    '\n",
    "    empty_space = '               '\n",
    "\n",
    "    write_list.append('n_clusters: %d\\n' % (n_clusters))\n",
    "    write_list.append('n_channels: 4\\n')\n",
    "    write_list.append('n_params: 2\\n')\n",
    "    write_list.append('times_used_in_Vt:%s' % ((tab + '0') * 4 + '\\n'))\n",
    "\n",
    "    zero_string = (tab + '0') * 8 + '\\n'\n",
    "\n",
    "    for cell_i in np.arange(n_clusters):\n",
    "        write_list.append(' cluster: %d center:%s' % (cell_i, zero_string))\n",
    "        write_list.append('%smin:%s' % (empty_space, zero_string))\n",
    "        write_list.append('%smax:%s' % (empty_space, zero_string))\n",
    "    write_list.append('\\nExact_cut_for: %s spikes: %d\\n' % (basename, n_spikes))\n",
    "\n",
    "    # The unit label array consists of 25 values per row in .cut file\n",
    "    n_rows = int(np.floor(n_spikes / 25))\n",
    "    remaining = int(n_spikes - n_rows * 25)\n",
    "\n",
    "    cut_string = ('%3u' * 25 + '\\n') * n_rows + '%3u' * remaining\n",
    "\n",
    "    write_list.append(cut_string % (tuple(unit_labels)))\n",
    "\n",
    "    with open(cut_filename, 'w') as f:\n",
    "        f.writelines(write_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d48bf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit ids: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "Tetrode ids: [0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "unit_ids = sorting_nwb.get_unit_ids()\n",
    "print('Unit ids:', unit_ids)\n",
    "\n",
    "tetrode_id = sorting_nwb.get_units_property(property_name='group')\n",
    "print('Tetrode ids:', tetrode_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "acecdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cut_filename_from_basename(filename, tetrode_id):\n",
    "    '''Given a str or Path object, assume the last entry after a slash\n",
    "    is a filename, strip any file suffix, add tetrode ID label, and\n",
    "    .cut suffix to name.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str or Path\n",
    "    tetrode_id : int\n",
    "    '''\n",
    "    return Path(str(filename).split('.')[0] + '_{}'.format(tetrode_id) + '.cut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "30098a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Axona_Tint_1ms/20201004_Tint.set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Axona_Tint_1ms/20201004_Tint_1.cut')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "filename = Path('/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Axona_Tint_1ms/20201004_Tint.set')\n",
    "print(filename)\n",
    "\n",
    "Path(str(filename.with_suffix('')) + '_{}'.format(1) + '.cut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2bcd8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to write .cut files separately for each tetrode, so we need\n",
    "# to get the spike_trains separately for each tetrode!\n",
    "\n",
    "def convert_sorting_extractor_to_cut(sorting_extractor, filename):\n",
    "    '''Write spike sorting output to .cut file, separately for each\n",
    "    tetrode.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sorting_extractor : spikeextractors.SortingExtractor\n",
    "    filename : str or Path\n",
    "        Full filename of .set file or base-filename (i.e. the part of the\n",
    "        filename all Axona files have in common). A given .cut file belongs\n",
    "        to a given tetrode file. For example, for tetrode `my_file.1`, the\n",
    "        corresponding cut_filename should be `my_file_1.cut`. This will be\n",
    "        set automatically given the base-filename or set file.\n",
    "        \n",
    "    TODO: Any reason one might want to only convert some tetrodes or some\n",
    "    samples? Should those be parameters?\n",
    "    '''\n",
    "    tetrode_ids = sorting_extractor.get_units_property(property_name='group')\n",
    "    tetrode_ids = np.array(tetrode_ids)\n",
    "    \n",
    "    unit_ids = np.array(sorting_extractor.get_unit_ids())\n",
    "    \n",
    "    for i in np.unique(tetrode_ids):\n",
    "        \n",
    "        print('Converting Tetrode {}'.format(i))\n",
    "\n",
    "        spike_train = sorting_extractor.get_units_spike_train(unit_ids=unit_ids[tetrode_ids==i])\n",
    "        unit_labels = convert_spike_train_to_label_array(spike_train)\n",
    "\n",
    "        # We use Axona conventions filenames (tetrodes are 1 indexed)\n",
    "        cut_filename = set_cut_filename_from_basename(filename, i + 1)\n",
    "        write_to_cut_file(cut_filename, unit_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ddcb99c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Tetrode 0\n",
      "Converting Tetrode 1\n",
      "Converting Tetrode 2\n",
      "Converting Tetrode 3\n"
     ]
    }
   ],
   "source": [
    "convert_sorting_extractor_to_cut(sorting_nwb, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a sortingextractor called sorting_nwb:\n",
    "spike_train = sorting_nwb.get_units_spike_train()\n",
    "unit_labels = convert_spike_train_to_label_array(spike_train)\n",
    "write_to_cut_file(cut_filename, unit_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d279934e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['firing_rate',\n",
       " 'group',\n",
       " 'halfwidth',\n",
       " 'isi_violation',\n",
       " 'max_channel',\n",
       " 'peak_to_valley',\n",
       " 'peak_trough_ratio',\n",
       " 'recovery_slope',\n",
       " 'repolarization_slope',\n",
       " 'snr',\n",
       " 'template']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorting_nwb.get_shared_unit_property_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33db57cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9403d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df9baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b67e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a853bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit ids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "Num. events for unit 1 = 101\n",
      "Num. events for first second of unit 1 = 59\n"
     ]
    }
   ],
   "source": [
    "# We saved sorting output as mountinsort `.mda` file\n",
    "\n",
    "sorting_MS4 = se.MdaSortingExtractor(\n",
    "    file_path=os.path.join(dir_name, 'mountainsort4.mda'),\n",
    "    sampling_frequency=48000\n",
    ")\n",
    "print('Unit ids = {}'.format(sorting_MS4.get_unit_ids()))\n",
    "spike_train = sorting_MS4.get_unit_spike_train(unit_id=1)\n",
    "print('Num. events for unit 1 = {}'.format(len(spike_train)))\n",
    "spike_train1 = sorting_MS4.get_unit_spike_train(unit_id=1, start_frame=0, end_frame=30000)\n",
    "print('Num. events for first second of unit 1 = {}'.format(len(spike_train1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3be7196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also have sorting data exported in `.nwb` format\n",
    "\n",
    "nwb_dir = Path(dir_name, 'nwb')\n",
    "sorting_nwb = se.NwbSortingExtractor(nwb_dir / 'axona_se_MS4.nwb', sampling_frequency=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8edbcc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spikeextractors.extractors.mdaextractors.mdaextractors.MdaSortingExtractor'>\n",
      "<class 'spikeextractors.extractors.nwbextractors.nwbextractors.NwbSortingExtractor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sorting_MS4))\n",
    "print(type(sorting_nwb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6e4e5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spikeextractors.extractors.nwbextractors.nwbextractors.NwbSortingExtractor at 0x7f7ce3b9c910>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorting_nwb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e609a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spikeextractors.extractors.mdaextractors.mdaextractors.MdaSortingExtractor at 0x7f7ce3fcaa30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorting_MS4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93001b75",
   "metadata": {},
   "source": [
    "I am not sure how we should best package the conversion to TINT in the end, for now we just need the different conversion methods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83a15467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorting_nwb.get_sampling_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b680a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_tetrode_file(sorting_extractor, save_dir):\n",
    "    '''Given a sorting extractor object create .X (tetrode) files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sorting_extractor : spikeextractors.SortingExtractor\n",
    "    save_dir : str or Path\n",
    "        Directory where to save the output\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_clu_file(sorting_extractor, save_dir):\n",
    "    '''Given a sorting extractor object create .clu files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sorting_extractor : spikeextractors.SortingExtractor\n",
    "    save_dir : str or Path\n",
    "        Directory where to save the output\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aadad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_cut_file(sorting_extractor, save_dir):\n",
    "    '''Given a sorting extractor object create .cut files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sorting_extractor : spikeextractors.SortingExtractor\n",
    "    save_dir : str or Path\n",
    "        Directory where to save the output\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa79b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077704de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_tint(sorting_extractor, save_dir):\n",
    "    '''Given a sorting extractor object, write appropriate data\n",
    "    to TINT format (from Axona). Will therefore create .X (tetrode)\n",
    "    and .clu (spike sorting information) files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sorting_extractor : spikeextractors.SortingExtractor\n",
    "    save_dir : str or Path\n",
    "        Directory where to save the output\n",
    "    '''\n",
    "    \n",
    "    write_to_tetrode_file(sorting_extractor, save_dir)\n",
    "    write_to_clu_file(sorting_extractor, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760fd273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ada07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107bd694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cdf576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379e754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975056dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e5e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikeinterface",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
