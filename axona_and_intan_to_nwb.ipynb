{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6658dc45",
   "metadata": {},
   "source": [
    "# Axona to NWB\n",
    "\n",
    "Convert Axona raw (`.bin` + `.set`) or unit data (`.X`, `.pos`, `.eeg`, `.egf`) to NWB format. \n",
    "\n",
    "It might be handy to convert the position data in the `.bin` file to a `.pos` file, allowing us to use the same code for both axona formats, as well as the Intan format later on (requiring the Hussaini lab to create their own `.pos` files based on the position tracking used). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d8a7ac",
   "metadata": {},
   "source": [
    "### Using nwb-conversion-tools directly\n",
    "\n",
    "It seems that I cannot use the datainterfaces directly (at least not AxonaRecordingExtractorInterface), because I get a datetime error: \n",
    "\n",
    "`TypeError: NWBFile.__init__: incorrect type for 'session_start_time' (got 'str', expected 'datetime')`. \n",
    "\n",
    "This is somewhat annoying, since when using NWBConverters it should be an ISO datetime string. Instead, let's simply create Converters for each situation and not use datainterfaces directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6a038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pynwb import NWBHDF5IO\n",
    "from nwbwidgets import nwb2widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2823aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_conversion_tools import (\n",
    "    NWBConverter,\n",
    "    AxonaRecordingExtractorInterface,\n",
    "    AxonaUnitRecordingExtractorInterface,\n",
    "    AxonaPositionDataInterface,\n",
    "    AxonaLFPDataInterface\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "629793ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to select a set-filename for which we also have raw, tetrode, eeg, egf and pos data.\n",
    "\n",
    "filename = '/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.set'\n",
    "filename_eeg = filename.replace('.set', '.eeg')\n",
    "filename_egf = filename.replace('.set', '.egf')\n",
    "\n",
    "base_dir = Path(filename).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd69c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make NWBConverters from datainterfaces for sensible combinations of datainterfaces\n",
    "\n",
    "class HussainiBinNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        AxonaRecordingExtractorInterface=AxonaRecordingExtractorInterface\n",
    "    )\n",
    "\n",
    "\n",
    "class HussainiBinPosLfpNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        AxonaRecordingExtractorInterface=AxonaRecordingExtractorInterface,\n",
    "        AxonaPositionDataInterface=AxonaPositionDataInterface,\n",
    "        AxonaLFPDataInterface=AxonaLFPDataInterface\n",
    "    )\n",
    "\n",
    "    \n",
    "class HussainiTetrodeNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        AxonaUnitRecordingExtractorInterface=AxonaUnitRecordingExtractorInterface\n",
    "    )\n",
    "    \n",
    "    \n",
    "class HussainiPosNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        AxonaPositionDataInterface=AxonaPositionDataInterface\n",
    "    )\n",
    "\n",
    "\n",
    "class HussainiLfpNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        AxonaLFPDataInterface=AxonaLFPDataInterface\n",
    "    )\n",
    "\n",
    "\n",
    "class HussainiUnitNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        AxonaUnitRecordingExtractorInterface=AxonaUnitRecordingExtractorInterface,\n",
    "        AxonaPositionDataInterface=AxonaPositionDataInterface,\n",
    "        AxonaLFPDataInterface=AxonaLFPDataInterface\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e5a39",
   "metadata": {},
   "source": [
    "1. __HussainiBinPosLfpNWBConverter__: `.bin` + `.pos` + `.eeg` + `.set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e707569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"AxonaLFPDataInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.eeg\"\n",
      "  },\n",
      "  \"AxonaRecordingExtractorInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.set\"\n",
      "  },\n",
      "  \"AxonaPositionDataInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.set\"\n",
      "  }\n",
      "}\n",
      "Source data is valid!\n",
      "Metadata is valid!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbuergers/spikeinterface/hussaini-test-pipeline/venv/lib/python3.8/site-packages/pynwb/file.py:801: UserWarning: Date is missing timezone information. Updating to local timezone.\n",
      "  warn(\"Date is missing timezone information. Updating to local timezone.\")\n",
      "/home/sbuergers/spikeinterface/hussaini-test-pipeline/venv/lib/python3.8/site-packages/hdmf/common/table.py:447: UserWarning: An attribute 'name' already exists on DynamicTable 'electrodes' so this column cannot be accessed as an attribute, e.g., table.name; it can only be accessed using other methods, e.g., table['name'].\n",
      "  warn(msg)\n",
      "/home/sbuergers/spikeinterface/nwb-conversion-tools/nwb_conversion_tools/utils/spike_interface.py:302: UserWarning: cannot create electrodes for this recording as ids already exist\n",
      "  warnings.warn(\"cannot create electrodes for this recording as ids already exist\")\n",
      "/home/sbuergers/spikeinterface/hussaini-test-pipeline/venv/lib/python3.8/site-packages/spikeextractors/extraction_tools.py:802: UserWarning: The recording extractor does not have unscaled traces. Returning scaled traces\n",
      "  warnings.warn(\"The recording extractor does not have unscaled traces. Returning scaled traces\")\n",
      "/home/sbuergers/spikeinterface/hussaini-test-pipeline/venv/lib/python3.8/site-packages/hdmf/build/objectmapper.py:256: DtypeConversionWarning: Spec 'SpatialSeries/timestamps': Value with data type int64 is being converted to data type float64 as specified.\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWB file saved at /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/nwb_test_bin_pos_lfp.nwb!\n"
     ]
    }
   ],
   "source": [
    "#1. __HussainiBinPosLfpNWBConverter__: `.bin` + `.pos` + `.eeg` + `.set`\n",
    "\n",
    "# Set nwbfile name\n",
    "nwbfile_name = 'nwb_test_bin_pos_lfp.nwb'\n",
    "\n",
    "\n",
    "# Specify source data\n",
    "source_data = dict(\n",
    "    AxonaLFPDataInterface=dict(filename=filename_eeg),\n",
    "    AxonaRecordingExtractorInterface=dict(filename=filename),\n",
    "    AxonaPositionDataInterface=dict(filename=filename),\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Initialize Converter\n",
    "converter = HussainiBinPosLfpNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / nwbfile_name\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata,\n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f84845",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root pynwb.file.NWBFile at 0x140662105252816\n",
      "Fields:\n",
      "  acquisition: {\n",
      "    ElectricalSeries_raw <class 'pynwb.ecephys.ElectricalSeries'>\n",
      "  }\n",
      "  devices: {\n",
      "    Axona <class 'pynwb.device.Device'>\n",
      "  }\n",
      "  electrode_groups: {\n",
      "    Group0 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group1 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group2 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group3 <class 'pynwb.ecephys.ElectrodeGroup'>\n",
      "  }\n",
      "  electrodes: electrodes <class 'hdmf.common.table.DynamicTable'>\n",
      "  experimenter: ['Abid']\n",
      "  file_create_date: [datetime.datetime(2021, 8, 7, 12, 56, 8, 138206, tzinfo=tzoffset(None, 7200))]\n",
      "  identifier: a2e4afe6-c434-47c7-8c89-90548c8a1304\n",
      "  processing: {\n",
      "    behavior <class 'pynwb.base.ProcessingModule'>,\n",
      "    ecephys <class 'pynwb.base.ProcessingModule'>\n",
      "  }\n",
      "  session_start_time: 2020-10-04 11:07:07+02:00\n",
      "  timestamps_reference_time: 2020-10-04 11:07:07+02:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72bb8859ca4435fad89220e51fde507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='session_description:', layout=Layout(max_height='40px', max_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check NWB file\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)\n",
    "    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4efc1",
   "metadata": {},
   "source": [
    "2. __HussainiBinNWBConverter__: `.bin` + `.set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e97843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"AxonaRecordingExtractorInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.set\"\n",
      "  }\n",
      "}\n",
      "Source data is valid!\n",
      "Metadata is valid!\n",
      "NWB file saved at /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/nwb_test_bin.nwb!\n",
      "root pynwb.file.NWBFile at 0x140661462403392\n",
      "Fields:\n",
      "  acquisition: {\n",
      "    ElectricalSeries_raw <class 'pynwb.ecephys.ElectricalSeries'>\n",
      "  }\n",
      "  devices: {\n",
      "    Axona <class 'pynwb.device.Device'>\n",
      "  }\n",
      "  electrode_groups: {\n",
      "    Group0 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group1 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group2 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group3 <class 'pynwb.ecephys.ElectrodeGroup'>\n",
      "  }\n",
      "  electrodes: electrodes <class 'hdmf.common.table.DynamicTable'>\n",
      "  experimenter: ['Abid']\n",
      "  file_create_date: [datetime.datetime(2021, 8, 7, 12, 56, 11, 66643, tzinfo=tzoffset(None, 7200))]\n",
      "  identifier: 32303dbe-e9c6-4232-81bb-9cfb4bc7fab3\n",
      "  session_start_time: 2020-10-04 11:07:07+02:00\n",
      "  timestamps_reference_time: 2020-10-04 11:07:07+02:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b90a357e67a492890550ca618baf05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='session_description:', layout=Layout(max_height='40px', max_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1. __HussainiBinPosLfpNWBConverter__: `.bin` + `.set`\n",
    "\n",
    "# Set nwbfile name\n",
    "nwbfile_name = 'nwb_test_bin.nwb'\n",
    "\n",
    "\n",
    "# Specify source data\n",
    "source_data = dict(\n",
    "    AxonaRecordingExtractorInterface=dict(filename=filename)\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Initialize Converter\n",
    "converter = HussainiBinNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / nwbfile_name\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata,\n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")\n",
    "\n",
    "\n",
    "# Check NWB file\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)\n",
    "    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344597a",
   "metadata": {},
   "source": [
    "3. __HussainiTetrodeNWBConverter__: `.X` + `.set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84dbf1f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"AxonaUnitRecordingExtractorInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.set\"\n",
      "  }\n",
      "}\n",
      "Source data is valid!\n",
      "Metadata is valid!\n",
      "NWB file saved at /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/nwb_test_tetrode.nwb!\n",
      "root pynwb.file.NWBFile at 0x140661454900768\n",
      "Fields:\n",
      "  acquisition: {\n",
      "    ElectricalSeries_raw <class 'pynwb.ecephys.ElectricalSeries'>\n",
      "  }\n",
      "  devices: {\n",
      "    Axona <class 'pynwb.device.Device'>\n",
      "  }\n",
      "  electrode_groups: {\n",
      "    Group0 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group1 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group2 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group3 <class 'pynwb.ecephys.ElectrodeGroup'>\n",
      "  }\n",
      "  electrodes: electrodes <class 'hdmf.common.table.DynamicTable'>\n",
      "  experimenter: ['Abid']\n",
      "  file_create_date: [datetime.datetime(2021, 8, 7, 12, 56, 13, 346585, tzinfo=tzoffset(None, 7200))]\n",
      "  identifier: 20648916-d51a-484d-a9bb-ec7bd67341dd\n",
      "  session_start_time: 2020-10-04 11:07:07+02:00\n",
      "  timestamps_reference_time: 2020-10-04 11:07:07+02:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9861ff78dc540668492c834bbba296e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='session_description:', layout=Layout(max_height='40px', max_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set nwbfile name\n",
    "nwbfile_name = 'nwb_test_tetrode.nwb'\n",
    "\n",
    "\n",
    "# Specify source data\n",
    "source_data = dict(\n",
    "    AxonaUnitRecordingExtractorInterface=dict(filename=filename)\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Initialize Converter\n",
    "converter = HussainiTetrodeNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / nwbfile_name\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata,\n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")\n",
    "\n",
    "\n",
    "# Check NWB file\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)\n",
    "    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd474cc8",
   "metadata": {},
   "source": [
    "4. __HussainiPosNWBConverter__: `.pos` + `.set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8475b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"AxonaPositionDataInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.set\"\n",
      "  }\n",
      "}\n",
      "Source data is valid!\n",
      "Metadata is valid!\n",
      "NWB file saved at /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/nwb_test_pos.nwb!\n",
      "root pynwb.file.NWBFile at 0x140661462259888\n",
      "Fields:\n",
      "  file_create_date: [datetime.datetime(2021, 8, 7, 12, 56, 15, 302932, tzinfo=tzoffset(None, 7200))]\n",
      "  identifier: 39e076c5-6d26-4f90-8c6d-9502ae74c2f9\n",
      "  processing: {\n",
      "    behavior <class 'pynwb.base.ProcessingModule'>\n",
      "  }\n",
      "  session_description: no description\n",
      "  session_start_time: 1970-01-01 00:00:00+01:00\n",
      "  timestamps_reference_time: 1970-01-01 00:00:00+01:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06aa2d9a58854ebaaee86cf77ea2dc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='session_description:', layout=Layout(max_height='40px', max_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set nwbfile name\n",
    "nwbfile_name = 'nwb_test_pos.nwb'\n",
    "\n",
    "\n",
    "# Specify source data\n",
    "source_data = dict(\n",
    "    AxonaPositionDataInterface=dict(filename=filename),\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Initialize Converter\n",
    "converter = HussainiPosNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / nwbfile_name\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata,\n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")\n",
    "\n",
    "\n",
    "# Check NWB file\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)\n",
    "    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d04fc5",
   "metadata": {},
   "source": [
    "5. __HussainiLfpNWBConverter__: `.eeg` + `.set`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d050ff42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"AxonaLFPDataInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.eeg\"\n",
      "  }\n",
      "}\n",
      "Source data is valid!\n",
      "Metadata is valid!\n",
      "NWB file saved at /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/nwb_test_lfp_eeg.nwb!\n",
      "root pynwb.file.NWBFile at 0x140661471265936\n",
      "Fields:\n",
      "  devices: {\n",
      "    Axona <class 'pynwb.device.Device'>\n",
      "  }\n",
      "  electrode_groups: {\n",
      "    Group0 <class 'pynwb.ecephys.ElectrodeGroup'>\n",
      "  }\n",
      "  electrodes: electrodes <class 'hdmf.common.table.DynamicTable'>\n",
      "  experimenter: ['Abid']\n",
      "  file_create_date: [datetime.datetime(2021, 8, 7, 12, 56, 17, 590463, tzinfo=tzoffset(None, 7200))]\n",
      "  identifier: e730cfa0-b77f-4a46-9e5e-ea5ddb518ef6\n",
      "  processing: {\n",
      "    ecephys <class 'pynwb.base.ProcessingModule'>\n",
      "  }\n",
      "  session_start_time: 2020-10-04 11:07:07+02:00\n",
      "  timestamps_reference_time: 2020-10-04 11:07:07+02:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913b205f31744594ab998bc31b9629a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='session_description:', layout=Layout(max_height='40px', max_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set nwbfile name\n",
    "nwbfile_name = 'nwb_test_lfp_eeg.nwb'\n",
    "\n",
    "\n",
    "# Specify source data\n",
    "source_data = dict(\n",
    "    AxonaLFPDataInterface=dict(filename=filename_eeg)\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Initialize Converter\n",
    "converter = HussainiLfpNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / nwbfile_name\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata,\n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")\n",
    "\n",
    "\n",
    "# Check NWB file\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)\n",
    "    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521cbca",
   "metadata": {},
   "source": [
    "6. __HussainiLfpNWBConverter__: `.egf` + `.set`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78628f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"AxonaLFPDataInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.egf\"\n",
      "  }\n",
      "}\n",
      "Source data is valid!\n",
      "Metadata is valid!\n",
      "NWB file saved at /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/nwb_test_lfp_egf.nwb!\n",
      "root pynwb.file.NWBFile at 0x140661469818544\n",
      "Fields:\n",
      "  devices: {\n",
      "    Axona <class 'pynwb.device.Device'>\n",
      "  }\n",
      "  electrode_groups: {\n",
      "    Group0 <class 'pynwb.ecephys.ElectrodeGroup'>\n",
      "  }\n",
      "  electrodes: electrodes <class 'hdmf.common.table.DynamicTable'>\n",
      "  experimenter: ['Abid']\n",
      "  file_create_date: [datetime.datetime(2021, 8, 7, 12, 56, 20, 731439, tzinfo=tzoffset(None, 7200))]\n",
      "  identifier: 9d3b5dc4-c59b-40cd-a065-c073db88370c\n",
      "  processing: {\n",
      "    ecephys <class 'pynwb.base.ProcessingModule'>\n",
      "  }\n",
      "  session_start_time: 2020-10-04 11:07:07+02:00\n",
      "  timestamps_reference_time: 2020-10-04 11:07:07+02:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a209f2f14d2f4760b7938c88b5a903f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='session_description:', layout=Layout(max_height='40px', max_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set nwbfile name\n",
    "nwbfile_name = 'nwb_test_lfp_egf.nwb'\n",
    "\n",
    "\n",
    "# Specify source data\n",
    "source_data = dict(\n",
    "    AxonaLFPDataInterface=dict(filename=filename_egf)\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Initialize Converter\n",
    "converter = HussainiLfpNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / nwbfile_name\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata,\n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")\n",
    "\n",
    "\n",
    "# Check NWB file\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)\n",
    "    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f535aa",
   "metadata": {},
   "source": [
    "7. __HussainiUnitNWBConverter__: `.X` + `.pos` + `.eeg` + `.set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "558961d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"AxonaLFPDataInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.eeg\"\n",
      "  },\n",
      "  \"AxonaUnitRecordingExtractorInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.set\"\n",
      "  },\n",
      "  \"AxonaPositionDataInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.set\"\n",
      "  }\n",
      "}\n",
      "Source data is valid!\n",
      "Metadata is valid!\n",
      "NWB file saved at /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/nwb_test_unit_eeg.nwb!\n",
      "root pynwb.file.NWBFile at 0x140661466742544\n",
      "Fields:\n",
      "  acquisition: {\n",
      "    ElectricalSeries_raw <class 'pynwb.ecephys.ElectricalSeries'>\n",
      "  }\n",
      "  devices: {\n",
      "    Axona <class 'pynwb.device.Device'>\n",
      "  }\n",
      "  electrode_groups: {\n",
      "    Group0 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group1 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group2 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group3 <class 'pynwb.ecephys.ElectrodeGroup'>\n",
      "  }\n",
      "  electrodes: electrodes <class 'hdmf.common.table.DynamicTable'>\n",
      "  experimenter: ['Abid']\n",
      "  file_create_date: [datetime.datetime(2021, 8, 7, 12, 56, 23, 314006, tzinfo=tzoffset(None, 7200))]\n",
      "  identifier: f7321fd4-f68e-4568-968d-da59380c77a9\n",
      "  processing: {\n",
      "    behavior <class 'pynwb.base.ProcessingModule'>,\n",
      "    ecephys <class 'pynwb.base.ProcessingModule'>\n",
      "  }\n",
      "  session_start_time: 2020-10-04 11:07:07+02:00\n",
      "  timestamps_reference_time: 2020-10-04 11:07:07+02:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e553579e1954b53bcad4ed66e8a5cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='session_description:', layout=Layout(max_height='40px', max_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set nwbfile name\n",
    "nwbfile_name = 'nwb_test_unit_eeg.nwb'\n",
    "\n",
    "\n",
    "# Specify source data\n",
    "source_data = dict(\n",
    "    AxonaLFPDataInterface=dict(filename=filename_eeg),\n",
    "    AxonaUnitRecordingExtractorInterface=dict(filename=filename),\n",
    "    AxonaPositionDataInterface=dict(filename=filename),\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Initialize Converter\n",
    "converter = HussainiUnitNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / nwbfile_name\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata,\n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")\n",
    "\n",
    "\n",
    "# Check NWB file\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)\n",
    "    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea4ffb",
   "metadata": {},
   "source": [
    "8. __HussainiUnitNWBConverter__: `.X` + `.pos` + `.egf` + `.set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3071e44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"AxonaLFPDataInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.egf\"\n",
      "  },\n",
      "  \"AxonaUnitRecordingExtractorInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.set\"\n",
      "  },\n",
      "  \"AxonaPositionDataInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.set\"\n",
      "  }\n",
      "}\n",
      "Source data is valid!\n",
      "Metadata is valid!\n",
      "NWB file saved at /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/nwb_test_unit_egf.nwb!\n",
      "root pynwb.file.NWBFile at 0x140661457855488\n",
      "Fields:\n",
      "  acquisition: {\n",
      "    ElectricalSeries_raw <class 'pynwb.ecephys.ElectricalSeries'>\n",
      "  }\n",
      "  devices: {\n",
      "    Axona <class 'pynwb.device.Device'>\n",
      "  }\n",
      "  electrode_groups: {\n",
      "    Group0 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group1 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group2 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group3 <class 'pynwb.ecephys.ElectrodeGroup'>\n",
      "  }\n",
      "  electrodes: electrodes <class 'hdmf.common.table.DynamicTable'>\n",
      "  experimenter: ['Abid']\n",
      "  file_create_date: [datetime.datetime(2021, 8, 7, 12, 56, 27, 341459, tzinfo=tzoffset(None, 7200))]\n",
      "  identifier: 4b7bfa61-6e68-494c-a5ff-49a4fb9acb75\n",
      "  processing: {\n",
      "    behavior <class 'pynwb.base.ProcessingModule'>,\n",
      "    ecephys <class 'pynwb.base.ProcessingModule'>\n",
      "  }\n",
      "  session_start_time: 2020-10-04 11:07:07+02:00\n",
      "  timestamps_reference_time: 2020-10-04 11:07:07+02:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a69af899014346a4f853d4c3f8067c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='session_description:', layout=Layout(max_height='40px', max_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set nwbfile name\n",
    "nwbfile_name = 'nwb_test_unit_egf.nwb'\n",
    "\n",
    "\n",
    "# Specify source data\n",
    "source_data = dict(\n",
    "    AxonaLFPDataInterface=dict(filename=filename_egf),\n",
    "    AxonaUnitRecordingExtractorInterface=dict(filename=filename),\n",
    "    AxonaPositionDataInterface=dict(filename=filename),\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Initialize Converter\n",
    "converter = HussainiUnitNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / nwbfile_name\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata,\n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")\n",
    "\n",
    "\n",
    "# Check NWB file\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)\n",
    "    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5d124",
   "metadata": {},
   "source": [
    "## Adding data to existing nwb files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0abcc",
   "metadata": {},
   "source": [
    "1. Add `.pos` and `.eeg` data to `.bin` acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c554d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"AxonaPositionDataInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.set\"\n",
      "  }\n",
      "}\n",
      "Source data is valid!\n",
      "Metadata is valid!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbuergers/spikeinterface/hussaini-test-pipeline/venv/lib/python3.8/site-packages/hdmf/common/table.py:447: UserWarning: An attribute 'name' already exists on DynamicTable 'electrodes' so this column cannot be accessed as an attribute, e.g., table.name; it can only be accessed using other methods, e.g., table['name'].\n",
      "  warn(msg)\n",
      "/home/sbuergers/spikeinterface/hussaini-test-pipeline/venv/lib/python3.8/site-packages/hdmf/build/objectmapper.py:256: DtypeConversionWarning: Spec 'SpatialSeries/timestamps': Value with data type int64 is being converted to data type float64 as specified.\n",
      "  warnings.warn(full_warning_msg, DtypeConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWB file saved at /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/nwb_test_bin.nwb!\n",
      "{\n",
      "  \"AxonaLFPDataInterface\": {\n",
      "    \"filename\": \"/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.eeg\"\n",
      "  }\n",
      "}\n",
      "Source data is valid!\n",
      "Metadata is valid!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbuergers/spikeinterface/nwb-conversion-tools/nwb_conversion_tools/utils/spike_interface.py:302: UserWarning: cannot create electrodes for this recording as ids already exist\n",
      "  warnings.warn(\"cannot create electrodes for this recording as ids already exist\")\n",
      "/home/sbuergers/spikeinterface/hussaini-test-pipeline/venv/lib/python3.8/site-packages/spikeextractors/extraction_tools.py:802: UserWarning: The recording extractor does not have unscaled traces. Returning scaled traces\n",
      "  warnings.warn(\"The recording extractor does not have unscaled traces. Returning scaled traces\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWB file saved at /mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/nwb_test_bin.nwb!\n",
      "root pynwb.file.NWBFile at 0x139924453646400\n",
      "Fields:\n",
      "  acquisition: {\n",
      "    ElectricalSeries_raw <class 'pynwb.ecephys.ElectricalSeries'>\n",
      "  }\n",
      "  devices: {\n",
      "    Axona <class 'pynwb.device.Device'>\n",
      "  }\n",
      "  electrode_groups: {\n",
      "    Group0 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group1 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group2 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
      "    Group3 <class 'pynwb.ecephys.ElectrodeGroup'>\n",
      "  }\n",
      "  electrodes: electrodes <class 'hdmf.common.table.DynamicTable'>\n",
      "  experimenter: ['Abid']\n",
      "  file_create_date: [datetime.datetime(2021, 8, 7, 12, 56, 11, 66643, tzinfo=tzoffset(None, 7200))]\n",
      "  identifier: 32303dbe-e9c6-4232-81bb-9cfb4bc7fab3\n",
      "  processing: {\n",
      "    behavior <class 'pynwb.base.ProcessingModule'>,\n",
      "    ecephys <class 'pynwb.base.ProcessingModule'>\n",
      "  }\n",
      "  session_start_time: 2020-10-04 11:07:07+02:00\n",
      "  timestamps_reference_time: 2020-10-04 11:07:07+02:00\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29852297fad2435d840982044128b100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='session_description:', layout=Layout(max_height='40px', max_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set nwbfile name\n",
    "nwbfile_name = 'nwb_test_bin.nwb'\n",
    "\n",
    "\n",
    "# Specify source data for pos\n",
    "source_data = dict(\n",
    "    AxonaPositionDataInterface=dict(filename=filename),\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Initialize Converter\n",
    "converter = HussainiPosNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / nwbfile_name\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata,\n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=False,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Specify source data for eeg\n",
    "source_data = dict(\n",
    "    AxonaLFPDataInterface=dict(filename=filename_eeg),\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Initialize Converter\n",
    "converter = HussainiLfpNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / nwbfile_name\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata,\n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=False,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")\n",
    "\n",
    "\n",
    "# Check NWB file\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)\n",
    "    \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d60dde",
   "metadata": {},
   "source": [
    "### Axona raw (`.bin` + `.set`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fea3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Old .bin file\n",
    "base_dir = Path('/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/')\n",
    "dir_name = base_dir / 'example_data_raw'\n",
    "base_filename = '20201004_Raw'\n",
    "\n",
    "# New .bin file\n",
    "base_dir = Path('/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/new_session_data')\n",
    "dir_name = base_dir / '06172021-HPC-B6-RAW'\n",
    "base_filename = '06172021-HPC-B6-RAW'\n",
    "filename = os.path.join(dir_name, base_filename)\n",
    "set_file = filename + '.set'\n",
    "bin_file = filename + '.bin'\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6778f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_conversion_tools import (\n",
    "    NWBConverter, AxonaRecordingExtractorInterface, AxonaPositionDataInterface\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148eb5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HussainiAxonaNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        AxonaRecordingExtractorInterface=AxonaRecordingExtractorInterface,\n",
    "        AxonaPositionDataInterface=AxonaPositionDataInterface\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd070ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from typing import Union, Optional\n",
    "from pathlib import Path\n",
    "import spikeextractors as se\n",
    "from pynwb import NWBFile\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "from nwb_conversion_tools.utils.json_schema import get_schema_from_method_signature, get_base_schema, fill_defaults\n",
    "from nwb_conversion_tools import SpikeGLXRecordingInterface\n",
    "from nwb_conversion_tools.datainterfaces.ecephys.axona.axonadatainterface import parse_generic_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify source data\n",
    "\n",
    "source_data = dict(\n",
    "    AxonaPositionDataInterface=dict(\n",
    "        filename=set_file\n",
    "    ),\n",
    "    AxonaRecordingExtractorInterface=dict(\n",
    "        filename=set_file\n",
    "    )\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HussainiAxonaNWBConverter\n",
    "\n",
    "converter = HussainiAxonaNWBConverter(source_data=source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata\n",
    "\n",
    "metadata = converter.get_metadata()\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata_schema from converter\n",
    "\n",
    "metadata_schema = converter.get_metadata_schema()\n",
    "\n",
    "print(json.dumps(metadata_schema['properties'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2107a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate metadata against metadata_schema\n",
    "\n",
    "validate(\n",
    "    instance=converter.get_metadata(),\n",
    "    schema=converter.get_metadata_schema()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f72455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_conversion_tools.utils.conversion_tools import (\n",
    "    get_default_nwbfile_metadata, make_nwbfile_from_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fda3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = base_dir / 'out_example.nwb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf14d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34150f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to NWB file\n",
    "\n",
    "output_file = base_dir / 'out_example.nwb'\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata,\n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NWB file\n",
    "\n",
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc5a057",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from nwbwidgets import nwb2widget\n",
    "\n",
    "output_file = base_dir / 'out_example.nwb'\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa4ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_conversion_tools.datainterfaces.ecephys.axona.axonadatainterface import get_position_object\n",
    "\n",
    "pos = get_position_object(filename=set_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eee72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwb.processing['behavior'].data_interfaces['Position'].spatial_series['t'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.spatial_series['t'].timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f6cef9",
   "metadata": {},
   "source": [
    "### Parse `.pos` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819630f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_conversion_tools.datainterfaces.ecephys.axona.axonadatainterface import parse_generic_header\n",
    "\n",
    "# Old pos file\n",
    "pos_file = '/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/sample_bin_to_tint/axona_sample.pos'\n",
    "\n",
    "# New pos file\n",
    "pos_file = '/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/new_session_data/06172021-HPC-B6-UNIT/06172021-HPC-B6-UNIT/06172021-B6-HPC-UNIT.pos'\n",
    "print(pos_file)\n",
    "\n",
    "pos_header = parse_generic_header(pos_file, None)\n",
    "pos_header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a57f8e",
   "metadata": {},
   "source": [
    "Data (with memory map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f40d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header_bstring(file):\n",
    "    \"\"\"\n",
    "    Scan file for the occurrence of 'data_start' and return the header\n",
    "    as byte string\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file (str or path): file to be loaded\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str: header byte content\n",
    "    \"\"\"\n",
    "\n",
    "    header = b''\n",
    "    with open(file, 'rb') as f:\n",
    "        for bin_line in f:\n",
    "            if b'data_start' in bin_line:\n",
    "                header += b'data_start'\n",
    "                break\n",
    "            else:\n",
    "                header += bin_line\n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pos_file, 'rb') as f:\n",
    "    print(f.read(532))\n",
    "    print(f.read(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5011b19",
   "metadata": {},
   "source": [
    "### LFP data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef36150",
   "metadata": {},
   "source": [
    "First, let's look at the tools from the Hussaini lab. And let's also remind ourselves what the file formats of .eeg and .egf data should look like:\n",
    "\n",
    "```\n",
    "EEG data is usually recorded continuously at 250 Hz in unit recording mode. The “.eeg” and “.eg2” files contain the data from the primary and secondary EEG channels, if these have been enabled. Very simply, the data consist of “num_EEG_samples” data bytes, following on from the data_start. The sample count is specified in the header. The “.egf” file is stored if a user selects a higher-sample rate EEG. Samples are normally collected at 4800 Hz (specified in the header), and are also normally 2 bytes long, rather than just 1.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc793a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hussaini lab tools: https://github.com/HussainiLab/BinConverter/blob/master/BinConverter/core/CreateEEG.py\n",
    "\n",
    "from BinConverter.core.CreateEEG import (\n",
    "    fir_hann, fir_hann, EEG_downsample, create_egf, write_eeg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcde0804",
   "metadata": {},
   "source": [
    "Try using a NumpyRecordingExtractor to ingest '.eeg' or '.egf' data.\n",
    "The user can ultimately specify whether to use .eeg or .egf data to be saved as LFP data in the nwb file. By default we\n",
    "will prefer .eeg data, since it has a lower sampling rate and is more memory efficient. In most cases researchers will\n",
    "not want to look at high frequency oscillations in LFP data.\n",
    "\n",
    "We can first extract the data of interest as a numpy ndarray, then create a NumpyRecordingExtractor for the nwb conversion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d0aa2",
   "metadata": {},
   "source": [
    "*  Case 1: Extract numpy ndarray from `.bin` data (very high Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67dd240",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_scaled = 100\n",
    "gain = 1.25\n",
    "offset = 10\n",
    "scaled = not_scaled * gain + offset\n",
    "\n",
    "print(scaled)\n",
    "\n",
    "unscaled = (scaled - offset) / gain\n",
    "\n",
    "print(unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa900bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_filt.get_channel_gains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ad4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = not_scaled * gain + offset\n",
    "\n",
    "non_scales = (scaled - offset) / gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "channel_ids = recording.get_channel_ids()\n",
    "traces = recording.get_traces(start_frame=0, end_frame=100, return_scaled=False)\n",
    "\n",
    "channel_idxs = np.array([recording.get_channel_ids().index(ch) for ch in channel_ids])\n",
    "gains = recording.get_channel_gains()[channel_idxs, None]\n",
    "offsets = recording.get_channel_offsets()[channel_idxs, None]\n",
    "unscaled = (scaled - offset) / gain\n",
    "\n",
    "traces = (traces.astype(\"float32\") * gains + offsets).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef50016",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.get_traces(start_frame=0, end_frame=100, return_scaled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c28d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "se.CacheRecordingExtractor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f4424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to avoid aliasing based on desired sampling frequency. The nyquest theorem states we need \n",
    "# twice the sampling rate of the highest frequency we are interested in. Conversely, we want to filter out all frequencies\n",
    "# higher than half our sampling rate. Since filters are not perfect and have a certain transition width until full\n",
    "# attenuation, we are conservative and choose sampling_rate / 2.25 as our cut-off high frequency threshold.\n",
    "\n",
    "import spiketoolkit as st\n",
    "\n",
    "sampling_rate = 250  # .eeg=250, .egf=4800\n",
    "\n",
    "recording_filt = st.preprocessing.bandpass_filter(recording, freq_min=0, freq_max=np.floor(sampling_rate / 2.25))\n",
    "\n",
    "#recording_downsamp = st.preprocessing.ResampleRecording(recording_filt, sampling_rate)\n",
    "\n",
    "channel_ids = recording.get_channel_ids()\n",
    "channel_idxs = np.array([recording.get_channel_ids().index(ch) for ch in channel_ids])\n",
    "gains = recording.get_channel_gains()[channel_idxs, None]\n",
    "offsets = recording.get_channel_offsets()[channel_idxs, None]\n",
    "unscaled = (recording_filt.get_traces() - offsets) / gains\n",
    "\n",
    "traces = (traces.astype(\"float32\") * gains + offsets).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to avoid aliasing based on desired sampling frequency. The nyquest theorem states we need \n",
    "# twice the sampling rate of the highest frequency we are interested in. Conversely, we want to filter out all frequencies\n",
    "# higher than half our sampling rate. Since filters are not perfect and have a certain transition width until full\n",
    "# attenuation, we are conservative and choose sampling_rate / 2.25 as our cut-off high frequency threshold.\n",
    "\n",
    "import spiketoolkit as st\n",
    "\n",
    "sampling_rate = 250  # .eeg=250, .egf=4800\n",
    "\n",
    "recording_filt = st.preprocessing.bandpass_filter(recording, freq_min=0, freq_max=np.floor(sampling_rate / 2.25))\n",
    "\n",
    "recording_downsamp = st.preprocessing.ResampleRecording(recording_filt, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba390ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "perma_cache_filename = os.path.join(dir_name, 'cached_data_eeg.dat') \n",
    "recording_cache = se.CacheRecordingExtractor(recording_filt, save_path = perma_cache_filename)\n",
    "recording_cache.dump_to_pickle(os.path.join(dir_name, 'cached_data_eeg.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a077a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cache = se.load_extractor_from_pickle(os.path.join(dir_name, 'cached_data_eeg.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fad425",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(recording_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444078da",
   "metadata": {},
   "source": [
    "*  Case 2: Extract numpy ndarray from `.eeg` data (low Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52981432",
   "metadata": {},
   "source": [
    "I believe I can simply extract the int8 or int16 data from an .eeg or .egf file, which corresponds to a particular EEG channel, and put it into a numpy recordingextractor (like Ben suggested). Then I only need to include the gain information for each channel and the metadata and I should be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f4183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eeg_sampling_frequency(filename):\n",
    "    \"\"\"\n",
    "    Read sampling frequency from .eegX or .egfX file header.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filename : Path or str\n",
    "        Full filename of Axona `.eegX` or `.egfX` file.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Fs : int\n",
    "        Sampling frequency\n",
    "    \"\"\"\n",
    "    Fs_entry = parse_generic_header(eeg_fname, ['sample_rate'])\n",
    "    Fs = int(float(Fs_entry.get('sample_rate').split(' ')[0]))\n",
    "\n",
    "    return Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3883b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading .eegX or .egfX data (unscaled)\n",
    "\n",
    "from nwb_conversion_tools.datainterfaces.ecephys.axona.axonadatainterface import get_header_bstring\n",
    "\n",
    "def read_eeg_file_lfp_data(filename):\n",
    "    \"\"\"\n",
    "    Read LFP data from Axona `.eegX` or `.egfX` file.\n",
    "\n",
    "    Parameters:\n",
    "    -------\n",
    "    filename (Path or Str):\n",
    "        Full filename of Axona `.eegX` or `.egfX` file.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    np.memmap (nobs x 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    lfp_dtype = '>i1'\n",
    "    footer_size = len('\\r\\ndata_end\\r\\n')\n",
    "    header_size = len(get_header_bstring(filename))\n",
    "    num_bytes = os.path.getsize(filename) - header_size - footer_size\n",
    "\n",
    "    # .eeg files are int8, .egf files are int16\n",
    "    if str(filename).split('.')[1][0:3] == 'egf':\n",
    "        lfp_dtype = '>i2'\n",
    "        num_bytes = num_bytes // 2\n",
    "\n",
    "    eeg_data = np.memmap(\n",
    "        filename=filename,\n",
    "        dtype=lfp_dtype,\n",
    "        mode='r',\n",
    "        offset=len(get_header_bstring(filename)),\n",
    "        shape=(1, num_bytes),\n",
    "    )\n",
    "\n",
    "    return eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073455f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_filenames(filename):\n",
    "    \"\"\"\n",
    "    Read LFP filenames of `.eeg` or `.egf` files in filename's directory.\n",
    "    E.g. if filename='/my/directory/my_file.eeg', all .eeg channels will be\n",
    "    appended to the output.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filename : path-like\n",
    "        Full filename of either .egg or .egf file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    path_list : list\n",
    "        List of filenames\n",
    "    \"\"\"\n",
    "    \n",
    "    suffix = Path(filename).suffix[0:4]\n",
    "    current_path = Path(filename).parent\n",
    "\n",
    "    path_list = [cur_path.name for cur_path in Path(filename).parent.rglob('*' + suffix + '*')]\n",
    "\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb472b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_eeg_file_lfp_data(filename):\n",
    "    \"\"\"\n",
    "    Read LFP data from all Axona `.eeg` or `.egf` files in filename's directory.\n",
    "    E.g. if filename='/my/directory/my_file.eeg', all .eeg channels will be conactenated\n",
    "    to a single np.array (chans x nobs). For .egf files substitude the file suffix.\n",
    "\n",
    "    Parameters:\n",
    "    -------\n",
    "    filename (Path or Str):\n",
    "        Full filename of Axona `.eeg` or `.egf` file.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    np.array (chans x obs)\n",
    "    \"\"\"\n",
    "\n",
    "    filename_list = get_all_filenames(filename)\n",
    "    parent_path = Path(filename).parent\n",
    "\n",
    "    eeg_memmaps = list()\n",
    "    sampling_rates = set()\n",
    "    for fname in filename_list:\n",
    "\n",
    "        sampling_rates.add(get_eeg_sampling_frequency(parent_path / fname))\n",
    "        \n",
    "        eeg_memmaps.append(read_eeg_file_lfp_data(parent_path / fname))\n",
    "\n",
    "    assert len(sampling_rates) < 2, 'File headers specify different sampling rates. Cannot combine EEG data.'\n",
    "    \n",
    "    eeg_data = np.concatenate(eeg_memmaps, axis=0)\n",
    "    \n",
    "    return eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6741c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_conversion_tools.datainterfaces.ecephys.baselfpextractorinterface import BaseLFPExtractorInterface\n",
    "from nwb_conversion_tools.datainterfaces.ecephys.axona.axonadatainterface import AxonaRecordingExtractorInterface\n",
    "from nwb_conversion_tools.utils.json_schema import get_schema_from_hdmf_class\n",
    "from nwb_conversion_tools.utils.spike_interface import write_recording\n",
    "from pynwb.ecephys import ElectricalSeries\n",
    "import spiketoolkit as st\n",
    "\n",
    "\n",
    "OptionalPathType = Optional[Union[str, Path]]\n",
    "\n",
    "\n",
    "def AxonaLFPNumpyExtractorWrapper(filename):\n",
    "    \"\"\"\n",
    "    Wrapper for instantiating a NumpyRecordingExtractor given an `.eeg` or `.egf` filename.\n",
    "    \"\"\"\n",
    "    return se.NumpyRecordingExtractor(\n",
    "        timeseries=read_all_eeg_file_lfp_data(filename),\n",
    "        sampling_frequency=get_eeg_sampling_frequency(filename)\n",
    "    )\n",
    "\n",
    "class AxonaLFPDataInterface(AxonaRecordingExtractorInterface):\n",
    "    \"\"\" ... \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def get_source_schema(cls):\n",
    "        return dict(\n",
    "            required=['filename'],\n",
    "            properties=dict(\n",
    "                filename=dict(\n",
    "                    type='string'\n",
    "                )\n",
    "            ),\n",
    "            type='object',\n",
    "            additionalProperties=False\n",
    "        )\n",
    "    \n",
    "    def __init__(self, **source_data):\n",
    "        self.recording_extractor = AxonaLFPNumpyExtractorWrapper(filename)\n",
    "        self.subset_channels = None\n",
    "        self.source_data = source_data\n",
    "        \n",
    "    def get_metadata_schema(self):\n",
    "        metadata_schema = super().get_metadata_schema()\n",
    "        metadata_schema[\"properties\"][\"Ecephys\"][\"properties\"].update(\n",
    "            ElectricalSeries_lfp=get_schema_from_hdmf_class(ElectricalSeries)\n",
    "        )\n",
    "        return metadata_schema\n",
    "\n",
    "    def get_metadata(self):\n",
    "        \"\"\"Retrieve Ecephys metadata specific to the Axona format.\"\"\"\n",
    "        metadata = super().get_metadata()\n",
    "        metadata['Ecephys'].pop('ElectricalSeries_raw', None)\n",
    "        metadata['Ecephys'].update(\n",
    "            ElectricalSeries_lfp=dict(\n",
    "                name=\"LFP\",\n",
    "                description=\"Local field potential signal.\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return metadata\n",
    "    \n",
    "    def run_conversion(\n",
    "        self,\n",
    "        nwbfile: NWBFile,\n",
    "        metadata: dict = None,\n",
    "        stub_test: bool = False,\n",
    "        use_times: bool = False,\n",
    "        save_path: OptionalPathType = None,\n",
    "        overwrite: bool = False,\n",
    "        buffer_mb: int = 500\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Primary function for converting low-pass recording extractor data to nwb.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        nwbfile: NWBFile\n",
    "            nwb file to which the recording information is to be added\n",
    "        metadata: dict\n",
    "            metadata info for constructing the nwb file (optional).\n",
    "            Should be of the format\n",
    "                metadata['Ecephys']['ElectricalSeries'] = dict(name=my_name, description=my_description)\n",
    "        use_times: bool\n",
    "            If True, the times are saved to the nwb file using recording.frame_to_time(). If False (default),\n",
    "            the sampling rate is used.\n",
    "        save_path: PathType\n",
    "            Required if an nwbfile is not passed. Must be the path to the nwbfile\n",
    "            being appended, otherwise one is created and written.\n",
    "        overwrite: bool\n",
    "            If using save_path, whether or not to overwrite the NWBFile if it already exists.\n",
    "        stub_test: bool, optional (default False)\n",
    "            If True, will truncate the data to run the conversion faster and take up less memory.\n",
    "        buffer_mb: int (optional, defaults to 500MB)\n",
    "            Maximum amount of memory (in MB) to use per iteration of the internal DataChunkIterator.\n",
    "            Requires trace data in the RecordingExtractor to be a memmap object.\n",
    "        \"\"\"\n",
    "        if stub_test or self.subset_channels is not None:\n",
    "            recording = self.subset_recording(stub_test=stub_test)\n",
    "        else:\n",
    "            recording = self.recording_extractor\n",
    "        write_recording(\n",
    "            recording=recording,\n",
    "            nwbfile=nwbfile,\n",
    "            metadata=metadata,\n",
    "            use_times=use_times,\n",
    "            write_as=\"lfp\",\n",
    "            es_key=\"ElectricalSeries_lfp\",\n",
    "            save_path=save_path,\n",
    "            overwrite=overwrite,\n",
    "            buffer_mb=buffer_mb\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I cannot get it to work with a child of BaseLFPExtractorInterface\n",
    "'''\n",
    "from nwb_conversion_tools.datainterfaces.ecephys.baselfpextractorinterface import BaseLFPExtractorInterface\n",
    "from nwb_conversion_tools.utils.json_schema import get_schema_from_hdmf_class\n",
    "from pynwb.ecephys import ElectricalSeries\n",
    "\n",
    "\n",
    "def AxonaLFPNumpyExtractorWrapper(filename):\n",
    "    \"\"\"\n",
    "    Wrapper for instantiating a NumpyRecordingExtractor given an `.eeg` or `.egf` filename.\n",
    "    \"\"\"\n",
    "    return se.NumpyRecordingExtractor(\n",
    "        timeseries=read_all_eeg_file_lfp_data(filename),\n",
    "        sampling_frequency=get_eeg_sampling_frequency(filename)\n",
    "    )\n",
    "\n",
    "class AxonaLFPDataInterface(BaseLFPExtractorInterface):\n",
    "    \"\"\" ... \"\"\"\n",
    "\n",
    "    RX = se.NumpyRecordingExtractor\n",
    "\n",
    "    @classmethod\n",
    "    def get_source_schema(cls):\n",
    "        return dict(\n",
    "                    required=['filename'],\n",
    "                    properties=dict(\n",
    "                        filename=dict(\n",
    "                            type='string'\n",
    "                        )\n",
    "                    ),\n",
    "                    type='object',\n",
    "                    additionalProperties=False\n",
    "                )\n",
    "    \n",
    "    def __init__(self, **source_data):\n",
    "        self.recording_extractor = AxonaLFPNumpyExtractorWrapper(filename)\n",
    "        self.subset_channels = None\n",
    "        self.source_data = source_data\n",
    "        \n",
    "    def get_metadata_schema(self):\n",
    "        metadata_schema = super().get_metadata_schema()\n",
    "        metadata_schema[\"properties\"][\"Ecephys\"][\"properties\"].update(\n",
    "            ElectricalSeries_lfp=get_schema_from_hdmf_class(ElectricalSeries)\n",
    "        )\n",
    "        return metadata_schema\n",
    "\n",
    "    def get_metadata(self):\n",
    "\n",
    "        # Extract information for specific parameters from .set file\n",
    "        params_of_interest = [\"experimenter\", \"comments\", \"duration\", \"sw_version\"]\n",
    "        set_file = self.source_data[\"filename\"].split(\".\")[0] + \".set\"\n",
    "        par = parse_generic_header(set_file, params_of_interest)\n",
    "\n",
    "#        # assign unique group to each channel, and fill in group_name property\n",
    "#        RX.set_channel_groups(\n",
    "#            groups=RX.get_channel_ids(),\n",
    "#            channel_ids=RX.get_channel_ids()\n",
    "#        )\n",
    "#        unique_elec_group_names = set(RX.get_channel_groups())\n",
    "\n",
    "#        for channel_id in RX.get_channel_ids():\n",
    "#            RX.set_channel_property(\n",
    "#                channel_id=channel_id,\n",
    "#                property_name=\"group_name\",\n",
    "#                value=f\"Group{channel_id}\"\n",
    "#            )\n",
    "\n",
    "        # Add available metadata\n",
    "        metadata = super().get_metadata()\n",
    "        metadata[\"NWBFile\"] = dict(\n",
    "            session_start_time=read_axona_iso_datetime(set_file),\n",
    "            session_description=par[\"comments\"],\n",
    "            experimenter=[par[\"experimenter\"]],\n",
    "        )\n",
    "\n",
    "        metadata[\"Ecephys\"] = dict(\n",
    "            Device=[\n",
    "                dict(\n",
    "                    name=\"Axona\",\n",
    "                    description=\"Axona DacqUSB, sw_version={}\".format(par[\"sw_version\"]),\n",
    "                    manufacturer=\"Axona\",\n",
    "                ),\n",
    "            ],\n",
    "            ElectrodeGroup=[\n",
    "                dict(\n",
    "                    name=f\"Group{group_name}\",\n",
    "                    location=\"\",\n",
    "                    device=\"Axona\",\n",
    "                    description=f\"Group {group_name} electrodes.\",\n",
    "                )\n",
    "                for group_name in unique_elec_group_names\n",
    "            ],\n",
    "            Electrodes=[\n",
    "                dict(\n",
    "                    name='group_name',\n",
    "                    description=\"The name of the ElectrodeGroup this electrode is a part of.\"\n",
    "                )\n",
    "            ],\n",
    "            ElectricalSeries_lfp=dict(\n",
    "                name=\"ElectricalSeries_lfp\",\n",
    "                description=\"EEG (lfp) acquisition traces.\"\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        return metadata\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309465fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_conversion_tools.datainterfaces.ecephys.axona.axonadatainterface import read_axona_iso_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_fname = '/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Axona_Tint_1ms/20201004_Tint.eeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = eeg_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ed9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_interface = AxonaLFPDataInterface(filename=eeg_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bbe74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HussainiAxonaNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        #AxonaRecordingExtractorInterface=AxonaRecordingExtractorInterface,\n",
    "        AxonaPositionDataInterface=AxonaPositionDataInterface,\n",
    "        AxonaLFPDataInterface=AxonaLFPDataInterface\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10398080",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Specify source data\n",
    "\n",
    "source_data = dict(\n",
    "    AxonaPositionDataInterface=dict(\n",
    "        filename=eeg_fname.replace('.eeg', '.set')\n",
    "    ),\n",
    "    #AxonaRecordingExtractorInterface=dict(\n",
    "    #    filename=eeg_fname.replace('.eeg', '.set')\n",
    "    #),\n",
    "    AxonaLFPDataInterface=dict(\n",
    "        filename=eeg_fname\n",
    "    )\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Instantiate converter\n",
    "converter = HussainiAxonaNWBConverter(source_data=source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c65dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate(\n",
    "    instance=lfp_interface.get_metadata(),\n",
    "    schema=lfp_interface.get_metadata_schema()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ffd69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "converter = HussainiAxonaNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "metadata\n",
    "\n",
    "\n",
    "# Get metadata_schema from converter\n",
    "metadata_schema = converter.get_metadata_schema()\n",
    "\n",
    "print(json.dumps(metadata_schema['properties'], indent=2))\n",
    "\n",
    "\n",
    "# Validate metadata against metadata_schema\n",
    "validate(\n",
    "    instance=converter.get_metadata(),\n",
    "    schema=converter.get_metadata_schema()\n",
    ")\n",
    "\n",
    "\n",
    "converter.get_metadata()\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / 'out_example.nwb'\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata, \n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e592aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NWB file\n",
    "\n",
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "output_file = base_dir / 'out_example.nwb'\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nwbwidgets import nwb2widget\n",
    "\n",
    "output_file = base_dir / 'out_example.nwb'\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f7782",
   "metadata": {},
   "source": [
    "The Axona format comes in the form of the raw data (`.bin` + `.set`) or Unit data (`.X`, `.set`, `.eegX` or `.egfX`, `.pos`). As such, a datainterface has to be somewhat flexible. \n",
    "\n",
    "We decided that it is not worth the effort to allow for a direct conversion from raw data to `nwb` including EEG and position data, since the Hussaini lab can already convert raw data to EEG and pos respectively. In addition, the converter for position data could also be used for `Intan` data, if the lab converts `Intan` to `.pos` themselves. \n",
    "\n",
    "Regarding the Unit data, I am not sure how or whether to add a datainterface that converts to `nwb` directly. As it stands the converted data would include the Gaussian noise added by the `AxonaUnitRecordingExtractor`. I do not really think that this is useful. In addition, if desired one could simply use the syntax from the tutorial notebook to export unit data to nwb.\n",
    "\n",
    "In general, lab specific data converters are a combination of multiple data interfaces. But in this case it might really depend on which data types the user has available and wants to convert. \n",
    "\n",
    "Currently, we can convert `.bin` file ecephys data, `.eeg` or `.egf` file data and `.pos` file data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09aac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a datainterface for unit data just for good measure\n",
    "\n",
    "class AxonaUnitRecordingExtractorInterface(AxonaRecordingExtractorInterface):\n",
    "    \"\"\"Primary data interface class for converting a AxonaRecordingExtractor\"\"\"\n",
    "\n",
    "    RX = se.AxonaUnitRecordingExtractor\n",
    "\n",
    "    @classmethod\n",
    "    def get_source_schema(cls):\n",
    "        return get_schema_from_method_signature(cls.__init__)\n",
    "\n",
    "    def __init__(self, **source_data):\n",
    "        self.recording_extractor=se.AxonaUnitRecordingExtractor(**source_data)\n",
    "        self.subset_channels = None\n",
    "        self.source_data = source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a datainterface for unit data just for good measure\n",
    "\n",
    "class AxonaUnitRecordingExtractorInterface(AxonaRecordingExtractorInterface):\n",
    "    \"\"\"Primary data interface class for converting a AxonaRecordingExtractor\"\"\"\n",
    "\n",
    "    RX = se.AxonaUnitRecordingExtractor\n",
    "\n",
    "    @classmethod\n",
    "    def get_source_schema(cls):\n",
    "        return dict(\n",
    "            required=['filename'],\n",
    "            properties=dict(\n",
    "                filename=dict(\n",
    "                    type='string'\n",
    "                ),\n",
    "            ),\n",
    "            type='object',\n",
    "            additionalProperties=True\n",
    "        )\n",
    "\n",
    "    def __init__(self, filename: str, noise_std=3.5):\n",
    "        super().__init__(filename=filename)\n",
    "        self.recording_extractor=se.AxonaUnitRecordingExtractor(filename=filename, noise_std=noise_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HussainiAxonaNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        AxonaUnitRecordingExtractorInterface=AxonaUnitRecordingExtractorInterface,\n",
    "        AxonaPositionDataInterface=AxonaPositionDataInterface,\n",
    "        AxonaLFPDataInterface=AxonaLFPDataInterface\n",
    "    )\n",
    "    \n",
    "# Specify source data\n",
    "source_data = dict(\n",
    "    AxonaPositionDataInterface=dict(\n",
    "        filename=eeg_fname.replace('.eeg', '.set')\n",
    "    ),\n",
    "    AxonaUnitRecordingExtractorInterface=dict(\n",
    "        filename=eeg_fname.replace('.eeg', '.set'),\n",
    "        noise_std=3.5\n",
    "    ),\n",
    "    AxonaLFPDataInterface=dict(\n",
    "        filename=eeg_fname\n",
    "    )\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "\n",
    "# Instantiate converter\n",
    "converter = HussainiAxonaNWBConverter(source_data=source_data)\n",
    "\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "metadata\n",
    "\n",
    "\n",
    "# Get metadata_schema from converter\n",
    "metadata_schema = converter.get_metadata_schema()\n",
    "print(json.dumps(metadata_schema['properties'], indent=2))\n",
    "\n",
    "\n",
    "# Validate metadata against metadata_schema\n",
    "validate(\n",
    "    instance=converter.get_metadata(),\n",
    "    schema=converter.get_metadata_schema()\n",
    ")\n",
    "\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / 'out_example3.nwb'\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata, \n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NWB file\n",
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "fname = output_file\n",
    "with NWBHDF5IO(fname, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nwbwidgets import nwb2widget\n",
    "\n",
    "output_file = base_dir / 'out_example3.nwb'\n",
    "\n",
    "io = NWBHDF5IO(output_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c0b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c12bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02155be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c53d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeba630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_test = '/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/new_session_data/out_example2.nwb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee33fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "axona_unit_interface.run_conversion??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84779f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = axona_unit_interface.get_metadata()\n",
    "\n",
    "nwb_test = axona_unit_interface.run_conversion(\n",
    "    nwbfile=None,\n",
    "    save_path=output_file_test,\n",
    "    metadata=metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb84d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf845d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3174bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286fd37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc69c40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e8bf73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45982e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b21b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a99d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bcc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read .eeg data with Hussaini lab tool\n",
    "\n",
    "import mmap\n",
    "import contextlib\n",
    "\n",
    "def ReadEEG(eeg_fname):\n",
    "    \"\"\"input:\n",
    "    eeg_filename: the fullpath to the eeg file that is desired to be read.\n",
    "    Example: C:\\Location\\of\\eegfile.eegX\n",
    "    Output:\n",
    "    The EEG waveform, and the sampling frequency\"\"\"\n",
    "\n",
    "    with open(eeg_fname, 'rb') as f:\n",
    "\n",
    "        is_eeg = False\n",
    "        if 'eeg' in eeg_fname:\n",
    "            is_eeg = True\n",
    "            # Fs = 250\n",
    "        # else:\n",
    "        #    Fs = 4.8e3\n",
    "\n",
    "        with contextlib.closing(mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)) as m:\n",
    "            # find the data_start\n",
    "            start_index = int(m.find(b'data_start') + len('data_start'))  # start of the data\n",
    "            stop_index = int(m.find(b'\\r\\ndata_end'))  # end of the data\n",
    "\n",
    "            sample_rate_start = m.find(b'sample_rate')\n",
    "            sample_rate_end = m[sample_rate_start:].find(b'\\r\\n')\n",
    "            Fs = float(m[sample_rate_start:sample_rate_start + sample_rate_end].decode('utf-8').split(' ')[1])\n",
    "\n",
    "            m = m[start_index:stop_index]\n",
    "\n",
    "            if is_eeg:\n",
    "                EEG = np.fromstring(m, dtype='>b')\n",
    "            else:\n",
    "                EEG = np.fromstring(m, dtype='<h')\n",
    "\n",
    "            return EEG, int(Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_fname = '/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Axona_Tint_1ms/20201004_Tint.eeg'\n",
    "\n",
    "eeg = read_eeg_file_lfp_data(eeg_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_huss = ReadEEG(eeg_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dcdf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eeg.shape)\n",
    "print(eeg[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68fa6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eeg_huss[0].shape)\n",
    "eeg_huss[0][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce3c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header_bstring(file):\n",
    "    \"\"\"\n",
    "    Scan file for the occurrence of 'data_start' and return the header\n",
    "    as byte string\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file (str or path): file to be loaded\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str: header byte content\n",
    "    \"\"\"\n",
    "    header = b''\n",
    "    with open(file, 'rb') as f:\n",
    "        for bin_line in f:\n",
    "            if b'data_start' in bin_line:\n",
    "                header += b'data_start'\n",
    "                break\n",
    "            else:\n",
    "                header += bin_line\n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399a947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(recording.neo_reader.get_analogsignal_chunk(channel_indexes=[15])[0:4800])\n",
    "plt.plot(recording.neo_reader.get_analogsignal_chunk(channel_indexes=[16])[0:4800])\n",
    "plt.plot(recording.neo_reader.get_analogsignal_chunk(channel_indexes=[17])[0:4800])\n",
    "plt.plot(recording.neo_reader.get_analogsignal_chunk(channel_indexes=[18])[0:4800])\n",
    "plt.plot(recording.neo_reader.get_analogsignal_chunk(channel_indexes=[19])[0:4800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sci\n",
    "\n",
    "f, Pxx_den = sci.signal.welch(\n",
    "    np.squeeze(recording.neo_reader.get_analogsignal_chunk(channel_indexes=[19])),\n",
    "    48000,\n",
    "    nperseg=1024\n",
    ")\n",
    "plt.semilogy(f, Pxx_den)\n",
    "plt.xlim([0, 5000])\n",
    "\n",
    "# If this is how the eeg data is saved in the .bin file, what is the point of the egf sampling rate of 4800 Hz?!\n",
    "# It looks like the data is already lowpass filtered at approximately 1000 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfe6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/HussainiLab/BinConverter/blob/master/BinConverter/core/Tint_Matlab.py\n",
    "from BinConverter.core.Tint_Matlab import get_active_eeg\n",
    "\n",
    "set_file_eeg = '/mnt/c/tmp_data/catalystneuro/sample_bin_to_tint/axona_sample.set'\n",
    "bin_file_eeg = '/mnt/c/tmp_data/catalystneuro/sample_bin_to_tint/axona_sample.bin'\n",
    "\n",
    "active_eeg_channels = get_active_eeg(set_file_eeg)\n",
    "active_eeg_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_eeg_channel_numbers = np.asarray(list(active_eeg_channels.values())) + 1\n",
    "active_eeg_channel_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in active_eeg_channel_numbers:\n",
    "\n",
    "    for eeg_number, eeg_chan_value in sorted(active_eeg_channels.items()):\n",
    "        if eeg_chan_value == channel - 1:\n",
    "            \n",
    "            print(eeg_number, eeg_chan_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f7c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BinConverter.core.readBin import get_bin_data\n",
    "\n",
    "EEG = get_bin_data(bin_file_eeg, channels=[channel])\n",
    "\n",
    "EEG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rx.get_traces?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0927d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ad3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rx = se.AxonaRecordingExtractor(filename=bin_file_eeg)\n",
    "\n",
    "rx.get_traces(return_scaled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c695b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_eeg(eeg_filename, EEG, Fs, DC_Blocker=self.dc_blocker.isChecked())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d40c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051b0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228becb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb026a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4655079",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_length = eeg_data.shape[0]\n",
    "print(eeg_length)\n",
    "print(eeg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_huss[0][0:eeg_length].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423cbe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(eeg_data, eeg_huss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c530c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_huss[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca274e",
   "metadata": {},
   "source": [
    "*  Case 3: Extract numpy ndarray from `.egf` data (high Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbae977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6270b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RX = se.NumpyRecordingExtractor()\n",
    "\n",
    "RX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236caf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "se.CacheRecordingExtractor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f231db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92554ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_conversion_tools.datainterfaces.ecephys.baselfpextractorinterface import BaseLFPExtractorInterface\n",
    "from nwb_conversion_tools.datainterfaces.ecephys.axona.axonadatainterface import AxonaRecordingExtractorInterface\n",
    "from nwb_conversion_tools.utils.json_schema import get_schema_from_hdmf_class\n",
    "from nwb_conversion_tools.utils.spike_interface import write_recording\n",
    "from pynwb.ecephys import ElectricalSeries\n",
    "import spiketoolkit as st\n",
    "\n",
    "\n",
    "OptionalPathType = Optional[Union[str, Path]]\n",
    "\n",
    "\n",
    "class AxonaLFPExtractorInterface(AxonaRecordingExtractorInterface):\n",
    "    \"\"\"...\"\"\"\n",
    "    \n",
    "    def __init__(self, filename: str):\n",
    "        super().__init__(filename=filename)\n",
    "        sampling_rate = 250  # .eeg=250, .egf=4800\n",
    "        print('Filtering and caching, this may take a few minutes ...')\n",
    "        recording_filt = st.preprocessing.bandpass_filter(\n",
    "            self.RX(filename=filename),\n",
    "            freq_min=0,\n",
    "            freq_max=np.floor(sampling_rate / 2.25)\n",
    "        )\n",
    "        recording_downsamp = st.preprocessing.ResampleRecording(recording_filt, sampling_rate)\n",
    "        recording_downsamp\n",
    "        self.recording_extractor = se.CacheRecordingExtractor(\n",
    "            recording_downsamp, return_scaled=False\n",
    "        )\n",
    "        self.subset_channels = None\n",
    "        \n",
    "    def get_metadata_schema(self):\n",
    "        metadata_schema = super().get_metadata_schema()\n",
    "        metadata_schema[\"properties\"][\"Ecephys\"][\"properties\"].update(\n",
    "            ElectricalSeries_lfp=get_schema_from_hdmf_class(ElectricalSeries)\n",
    "        )\n",
    "        return metadata_schema\n",
    "\n",
    "    def get_metadata(self):\n",
    "        \"\"\"Retrieve Ecephys metadata specific to the Axona format.\"\"\"\n",
    "        metadata = super().get_metadata()\n",
    "        metadata['Ecephys'].pop('ElectricalSeries_raw', None)\n",
    "        metadata['Ecephys'].update(\n",
    "            ElectricalSeries_lfp=dict(\n",
    "                name=\"LFP\",\n",
    "                description=\"Local field potential signal.\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return metadata\n",
    "    \n",
    "    def run_conversion(\n",
    "        self,\n",
    "        nwbfile: NWBFile,\n",
    "        metadata: dict = None,\n",
    "        stub_test: bool = False,\n",
    "        use_times: bool = False,\n",
    "        save_path: OptionalPathType = None,\n",
    "        overwrite: bool = False,\n",
    "        buffer_mb: int = 500\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Primary function for converting low-pass recording extractor data to nwb.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        nwbfile: NWBFile\n",
    "            nwb file to which the recording information is to be added\n",
    "        metadata: dict\n",
    "            metadata info for constructing the nwb file (optional).\n",
    "            Should be of the format\n",
    "                metadata['Ecephys']['ElectricalSeries'] = dict(name=my_name, description=my_description)\n",
    "        use_times: bool\n",
    "            If True, the times are saved to the nwb file using recording.frame_to_time(). If False (default),\n",
    "            the sampling rate is used.\n",
    "        save_path: PathType\n",
    "            Required if an nwbfile is not passed. Must be the path to the nwbfile\n",
    "            being appended, otherwise one is created and written.\n",
    "        overwrite: bool\n",
    "            If using save_path, whether or not to overwrite the NWBFile if it already exists.\n",
    "        stub_test: bool, optional (default False)\n",
    "            If True, will truncate the data to run the conversion faster and take up less memory.\n",
    "        buffer_mb: int (optional, defaults to 500MB)\n",
    "            Maximum amount of memory (in MB) to use per iteration of the internal DataChunkIterator.\n",
    "            Requires trace data in the RecordingExtractor to be a memmap object.\n",
    "        \"\"\"\n",
    "        if stub_test or self.subset_channels is not None:\n",
    "            recording = self.subset_recording(stub_test=stub_test)\n",
    "        else:\n",
    "            recording = self.recording_extractor\n",
    "        write_recording(\n",
    "            recording=recording,\n",
    "            nwbfile=nwbfile,\n",
    "            metadata=metadata,\n",
    "            use_times=use_times,\n",
    "            write_as=\"lfp\",\n",
    "            es_key=\"ElectricalSeries_lfp\",\n",
    "            save_path=save_path,\n",
    "            overwrite=overwrite,\n",
    "            buffer_mb=buffer_mb\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a163a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_filename = '/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/new_session_data/06172021-HPC-B6-RAW/06172021-HPC-B6-RAW.set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_raw = AxonaRecordingExtractorInterface(filename=set_filename)\n",
    "\n",
    "print(axo_raw.recording_extractor.get_shared_channel_property_names())\n",
    "\n",
    "axo_raw.get_metadata()\n",
    "axo_raw.recording_extractor.get_shared_channel_property_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7818db",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_lfp.source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18387d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_lfp = AxonaLFPExtractorInterface(filename=set_filename)\n",
    "\n",
    "print(axo_lfp.recording_extractor.get_shared_channel_property_names())\n",
    "\n",
    "axo_lfp.get_metadata()\n",
    "axo_lfp.recording_extractor.get_shared_channel_property_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4118d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_lfp.get_source_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84dc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_lfp.get_conversion_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b28c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_lfp.get_conversion_options_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5dd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_lfp.run_conversion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66ee6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de48c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = axo_lfp.get_metadata()\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import distutils.version\n",
    "from pathlib import Path\n",
    "from typing import Union, Optional, List\n",
    "from warnings import warn\n",
    "import psutil\n",
    "from collections import defaultdict\n",
    "\n",
    "import spikeextractors as se\n",
    "import pynwb\n",
    "from numbers import Real\n",
    "from hdmf.data_utils import DataChunkIterator\n",
    "from hdmf.backends.hdf5.h5_utils import H5DataIO\n",
    "#from .json_schema import dict_deep_update\n",
    "\n",
    "PathType = Union[str, Path, None]\n",
    "ArrayType = Union[list, np.ndarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26701616",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d007b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class HussainiAxonaNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        AxonaRecordingExtractorInterface=AxonaRecordingExtractorInterface,\n",
    "        AxonaPositionDataInterface=AxonaPositionDataInterface,\n",
    "        AxonaLFPExtractorInterface=AxonaLFPExtractorInterface\n",
    "    )\n",
    "    \n",
    "# Specify source data\n",
    "source_data = dict(\n",
    "#    AxonaPositionDataInterface=dict(\n",
    "#        filename=set_file\n",
    "#    ),\n",
    "#    AxonaRecordingExtractorInterface=dict(\n",
    "#        filename=set_file\n",
    "#    ),\n",
    "    AxonaLFPExtractorInterface=dict(\n",
    "        filename=set_file\n",
    "    )\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "# Initialize HussainiAxonaNWBConverter\n",
    "converter = HussainiAxonaNWBConverter(source_data=source_data)\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "# Validate metadata against metadata_schema\n",
    "validate(\n",
    "    instance=converter.get_metadata(),\n",
    "    schema=converter.get_metadata_schema()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aabfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HussainiAxonaNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        AxonaRecordingExtractorInterface=AxonaRecordingExtractorInterface,\n",
    "        AxonaPositionDataInterface=AxonaPositionDataInterface,\n",
    "        AxonaLFPExtractorInterface=AxonaLFPExtractorInterface\n",
    "    )\n",
    "    \n",
    "# Specify source data\n",
    "source_data = dict(\n",
    "    AxonaPositionDataInterface=dict(\n",
    "        filename=set_file\n",
    "    ),\n",
    "    AxonaRecordingExtractorInterface=dict(\n",
    "        filename=set_file\n",
    "    ),\n",
    "    AxonaLFPExtractorInterface=dict(\n",
    "        filename=set_file\n",
    "    )\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))\n",
    "\n",
    "# Initialize HussainiAxonaNWBConverter\n",
    "converter = HussainiAxonaNWBConverter(source_data=source_data)\n",
    "\n",
    "# Get metadata\n",
    "metadata = converter.get_metadata()\n",
    "\n",
    "# Validate metadata against metadata_schema\n",
    "validate(\n",
    "    instance=converter.get_metadata(),\n",
    "    schema=converter.get_metadata_schema()\n",
    ")\n",
    "\n",
    "# Export to NWB file\n",
    "output_file = base_dir / 'out_example_test5.nwb'\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata, \n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7f4dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the nwb file to see if we converted everything correctly\n",
    "\n",
    "io = NWBHDF5IO(output_file, 'r')\n",
    "nwbfile_in = io.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35248d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile_in.acquisition['ElectricalSeries_raw'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile_in.processing['ecephys'].data_interfaces['LFP'].electrical_series['LFP'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c81aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nwbfile_in.acquisition['ElectricalSeries_raw'].data[0:2300, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc55474",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nwbfile_in.processing['ecephys'].data_interfaces['LFP'].electrical_series['LFP'].data[0:12, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a7835",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_timeseries_in = nwbfile_in.processing['test_timeseries']\n",
    "print(test_timeseries_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eff0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac7049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2720cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43d436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fcf0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_raw = AxonaRecordingExtractorInterface(filename=set_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile = generate_nwb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5bf788",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = axo_raw.get_metadata()\n",
    "\n",
    "axo_raw.run_conversion(\n",
    "    nwbfile=make_nwbfile_from_metadata(metadata),\n",
    "    metadata=metadata,\n",
    "    overwrite=True,\n",
    "    write_as='raw'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39faf403",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = axo_lfp.get_metadata()\n",
    "\n",
    "axo_lfp.run_conversion(\n",
    "    nwbfile=make_nwbfile_from_metadata(metadata),\n",
    "    metadata=metadata,\n",
    "    overwrite=True,\n",
    "    write_as='lfp'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b031e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_raw.run_conversion??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988aaff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd333ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f9dadd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21f8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930cdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287f09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bec678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f203307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12bca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to NWB file\n",
    "output_file = base_dir / 'out_example_lfp.nwb'\n",
    "\n",
    "converter.run_conversion(\n",
    "    metadata=metadata, \n",
    "    nwbfile_path=output_file,\n",
    "    overwrite=True,\n",
    "    save_to_file=True,\n",
    "    conversion_options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec0ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3345042e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b336ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f777e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_conversion_tools.utils.spike_interface import add_electrode_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_raw = AxonaRecordingExtractorInterface(filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_lfp.recording_extractor.get_channel_property_names(channel_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e723059",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_raw.recording_extractor.get_channel_property_names(channel_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca931e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import distutils.version\n",
    "from pathlib import Path\n",
    "from typing import Union, Optional, List\n",
    "from warnings import warn\n",
    "import psutil\n",
    "from collections import defaultdict\n",
    "\n",
    "import spikeextractors as se\n",
    "import pynwb\n",
    "from numbers import Real\n",
    "from hdmf.data_utils import DataChunkIterator\n",
    "from hdmf.backends.hdf5.h5_utils import H5DataIO\n",
    "#from .json_schema import dict_deep_update\n",
    "\n",
    "PathType = Union[str, Path, None]\n",
    "ArrayType = Union[list, np.ndarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = axo_lfp.recording_extractor\n",
    "#recording = axo_raw.recording_extractor\n",
    "exclude = ()\n",
    "nwbfile = make_nwbfile_from_metadata(metadata=metadata)\n",
    "\n",
    "\n",
    "if nwbfile.electrodes is not None:\n",
    "    ids_absent = [id not in nwbfile.electrodes.id for id in recording.get_channel_ids()]\n",
    "    if not all(ids_absent):\n",
    "        warnings.warn('cannot create electrodes for this recording as ids already exist')\n",
    "\n",
    "if nwbfile is not None:\n",
    "    assert isinstance(nwbfile, pynwb.NWBFile), \"'nwbfile' should be of type pynwb.NWBFile\"\n",
    "if nwbfile.electrode_groups is None or len(nwbfile.electrode_groups) == 0:\n",
    "    add_electrode_groups(recording, nwbfile, metadata)\n",
    "# For older versions of pynwb, we need to manually add these columns\n",
    "if distutils.version.LooseVersion(pynwb.__version__) < '1.3.0':\n",
    "    if nwbfile.electrodes is None or 'rel_x' not in nwbfile.electrodes.colnames:\n",
    "        nwbfile.add_electrode_column('rel_x', 'x position of electrode in electrode group')\n",
    "    if nwbfile.electrodes is None or 'rel_y' not in nwbfile.electrodes.colnames:\n",
    "        nwbfile.add_electrode_column('rel_y', 'y position of electrode in electrode group')\n",
    "\n",
    "defaults = dict(\n",
    "    x=np.nan,\n",
    "    y=np.nan,\n",
    "    z=np.nan,\n",
    "    # There doesn't seem to be a canonical default for impedence, if missing.\n",
    "    # The NwbRecordingExtractor follows the -1.0 convention, other scripts sometimes use np.nan\n",
    "    imp=-1.0,\n",
    "    location=\"unknown\",\n",
    "    filtering=\"none\",\n",
    "    group_name=\"0\"\n",
    ")\n",
    "if metadata is None:\n",
    "    metadata = dict(Ecephys=dict())\n",
    "\n",
    "if 'Ecephys' not in metadata:\n",
    "    metadata['Ecephys'] = dict()\n",
    "\n",
    "if 'Electrodes' not in metadata['Ecephys']:\n",
    "    metadata['Ecephys']['Electrodes'] = []\n",
    "\n",
    "assert all([isinstance(x, dict) and set(x.keys()) == set(['name', 'description'])\n",
    "            for x in metadata['Ecephys']['Electrodes']]), \\\n",
    "    \"Expected metadata['Ecephys']['Electrodes'] to be a list of dictionaries, containing the keys 'name' and 'description'\"\n",
    "assert all([x['name'] != 'group' for x in metadata['Ecephys']['Electrodes']]), \\\n",
    "    \"Passing metadata field 'group' is deprecated; pass group_name instead!\"\n",
    "\n",
    "if nwbfile.electrodes is None:\n",
    "    nwb_elec_ids = []\n",
    "else:\n",
    "    nwb_elec_ids = nwbfile.electrodes.id.data[:]\n",
    "\n",
    "elec_columns = defaultdict(dict)  # dict(name: dict(description='',data=data, index=False))\n",
    "elec_columns_append = defaultdict(dict)\n",
    "property_names = set()\n",
    "for chan_id in recording.get_channel_ids():\n",
    "    for i in recording.get_channel_property_names(channel_id=chan_id):\n",
    "        property_names.add(i)\n",
    "\n",
    "# property 'brain_area' of RX channels corresponds to 'location' of NWB electrodes\n",
    "exclude_names = set(['location','group'] + list(exclude))\n",
    "\n",
    "channel_property_defaults = {\n",
    "    list: [],\n",
    "    np.ndarray: np.array(np.nan),\n",
    "    str: '',\n",
    "    Real: np.nan\n",
    "}\n",
    "found_property_types = {prop: Real for prop in property_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eabc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.get_channel_property_names(channel_id=chan_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "axo_lfp.recording_extractor.get_channel_property_names(channel_id=chan_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prop in property_names:\n",
    "    prop_skip = False\n",
    "    if prop not in exclude_names:\n",
    "        data = []\n",
    "        prop_chan_count = 0\n",
    "        # build data:\n",
    "        for chan_id in recording.get_channel_ids():\n",
    "            if prop in recording.get_channel_property_names(channel_id=chan_id):\n",
    "                prop_chan_count += 1\n",
    "                chan_data = recording.get_channel_property(channel_id=chan_id, property_name=prop)\n",
    "                # find the type and store (only when the first channel with given property is found):\n",
    "                if prop_chan_count==1:\n",
    "                    proptype = [proptype for proptype in channel_property_defaults if isinstance(chan_data, proptype)]\n",
    "                    if len(proptype) > 0:\n",
    "                        found_property_types[prop] = proptype[0]\n",
    "                        # cast as float if any number:\n",
    "                        if found_property_types[prop]==Real:\n",
    "                            chan_data = np.float(chan_data)\n",
    "                        # update data if wrong datatype items filled prior:\n",
    "                        if len(data) > 0 and not isinstance(data[-1], found_property_types[prop]):\n",
    "                            data = [channel_property_defaults[found_property_types[prop]]] * len(data)\n",
    "                    else:\n",
    "                        prop_skip = True  # skip storing that property if not of default type\n",
    "                        break\n",
    "                data.append(chan_data)\n",
    "            else:\n",
    "                data.append(channel_property_defaults[found_property_types[prop]])\n",
    "        # store data after build:\n",
    "        if not prop_skip:\n",
    "            index = found_property_types[prop] == ArrayType\n",
    "            prop_name_new = 'location' if prop == 'brain_area' else prop\n",
    "            found_property_types[prop_name_new] = found_property_types.pop(prop)\n",
    "            elec_columns[prop_name_new].update(description=prop_name_new, data=data, index=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbfc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in metadata['Ecephys']['Electrodes']:\n",
    "    elec_columns[x['name']]['description'] = x['description']\n",
    "    if x['name'] not in list(elec_columns):\n",
    "        raise ValueError(f'\"{x[\"name\"]}\" not a property of se object')\n",
    "\n",
    "# updating default arguments if electrodes table already present:\n",
    "default_updated = dict()\n",
    "if nwbfile.electrodes is not None:\n",
    "    for colname in nwbfile.electrodes.colnames:\n",
    "        if colname!='group':\n",
    "            samp_data = nwbfile.electrodes[colname].data[0]\n",
    "            default_datatype = [proptype for proptype in channel_property_defaults if isinstance(samp_data, proptype)][0]\n",
    "            default_updated.update({colname:channel_property_defaults[default_datatype]})\n",
    "default_updated.update(defaults)\n",
    "\n",
    "for name, des_dict in elec_columns.items():\n",
    "    des_args = dict(des_dict)\n",
    "    if name not in default_updated:\n",
    "        if nwbfile.electrodes is None:\n",
    "            nwbfile.add_electrode_column(name=name, description=des_args['description'], index=des_args['index'])\n",
    "        else:\n",
    "            # build default junk values for data to force add columns later:\n",
    "            combine_data = [channel_property_defaults[found_property_types[name]]] * len(nwbfile.electrodes.id)\n",
    "            des_args['data'] = combine_data + des_args['data']\n",
    "            elec_columns_append[name] = des_args\n",
    "\n",
    "for name in elec_columns_append:\n",
    "    _ = elec_columns.pop(name)\n",
    "\n",
    "for j, channel_id in enumerate(recording.get_channel_ids()):\n",
    "    if channel_id not in nwb_elec_ids:\n",
    "        electrode_kwargs = dict(default_updated)\n",
    "        electrode_kwargs.update(id=channel_id)\n",
    "\n",
    "        # recording.get_channel_locations defaults to np.nan if there are none\n",
    "        location = recording.get_channel_locations(channel_ids=channel_id)[0]\n",
    "        if all([not np.isnan(loc) for loc in location]):\n",
    "            # property 'location' of RX channels corresponds to rel_x and rel_ y of NWB electrodes\n",
    "            electrode_kwargs.update(\n",
    "                dict(\n",
    "                    rel_x=float(location[0]),\n",
    "                    rel_y=float(location[1])\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for name, desc in elec_columns.items():\n",
    "            if name == 'group_name':\n",
    "                group_name = str(desc['data'][j])\n",
    "                if group_name!='' and group_name not in nwbfile.electrode_groups:\n",
    "                    warnings.warn(f\"Electrode group {group_name} for electrode {channel_id} was not \"\n",
    "                                  \"found in the nwbfile! Automatically adding.\")\n",
    "                    missing_group_metadata = dict(\n",
    "                        Ecephys=dict(\n",
    "                            ElectrodeGroup=[dict(\n",
    "                                name=group_name,\n",
    "                            )]\n",
    "                        )\n",
    "                    )\n",
    "                    add_electrode_groups(recording, nwbfile, missing_group_metadata)\n",
    "                electrode_kwargs.update(\n",
    "                    dict(\n",
    "                        group=nwbfile.electrode_groups[group_name],\n",
    "                        group_name=group_name\n",
    "                    )\n",
    "                )\n",
    "            elif 'data' in desc:\n",
    "                electrode_kwargs[name] = desc['data'][j]\n",
    "\n",
    "        if 'group_name' not in elec_columns:\n",
    "            group_id = recording.get_channel_groups(channel_ids=channel_id)[0]\n",
    "            electrode_kwargs.update(\n",
    "                dict(\n",
    "                    group=nwbfile.electrode_groups[str(group_id)],\n",
    "                    group_name=str(group_id)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        nwbfile.add_electrode(**electrode_kwargs)\n",
    "# add columns for existing electrodes:\n",
    "for col_name, cols_args in elec_columns_append.items():\n",
    "    nwbfile.add_electrode_column(col_name,**cols_args)\n",
    "assert nwbfile.electrodes is not None, \\\n",
    "    \"Unable to form electrode table! Check device, electrode group, and electrode metadata.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689565b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7653618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea364f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.electrodes[colname].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = axo_lfp.get_metadata()\n",
    "\n",
    "nwbfile = make_nwbfile_from_metadata(metadata=metadata)\n",
    "\n",
    "axo_lfp.run_conversion(nwbfile, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f6f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b178d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934c00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06093c03",
   "metadata": {},
   "source": [
    "# Intan to NWB\n",
    "\n",
    "For this there are already resources from the Hussaini lab we should be able to use.\n",
    "\n",
    "See here: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eae801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_conversion_tools import (\n",
    "    NWBConverter, AxonaRecordingExtractorInterface, AxonaPositionDataInterface, IntanRecordingInterface\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f361f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_conversion_tools import IntanRecordingInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HussainiIntanNWBConverter(NWBConverter):\n",
    "    data_interface_classes = dict(\n",
    "        IntanRecordingInterface=IntanRecordingInterface,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "intan_file = '/mnt/d/freelance-work/catalyst-neuro/hussaini-lab-to-nwb/Intan_data/intan_rhd_test_1.rhd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e7c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify source data\n",
    "\n",
    "source_data = dict(\n",
    "    IntanRecordingInterface=dict(\n",
    "        file_path=intan_file\n",
    "    )\n",
    ")\n",
    "print(json.dumps(source_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HussainiIntanNWBConverter\n",
    "\n",
    "intan_converter = HussainiIntanNWBConverter(source_data=source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad4cd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get metadata_schema from converter\n",
    "\n",
    "metadata_schema = intan_converter.get_metadata_schema()\n",
    "\n",
    "print(json.dumps(metadata_schema['properties'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd197ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validate metadata against metadata_schema\n",
    "\n",
    "validate(\n",
    "    instance=intan_converter.get_metadata(),\n",
    "    schema=intan_converter.get_metadata_schema()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd7583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7082643f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146cc04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15a05a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (hussaini-test-pipeline)",
   "language": "python",
   "name": "hussaini-test-pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
