{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikeInterface Tutorial - NWB User Days Workshop  - September 2020\n",
    "\n",
    "\n",
    "In this tutorial, we will cover the basics of using SpikeInterface for extracellular analysis and spike sorting comparison. We will be using the `spikeinterface` from the SpikeInterface github organization. \n",
    "\n",
    "`spikeinterface` wraps 5 subpackages: `spikeextractors`, `spikesorters`, `spiketoolkit`, `spikecomparison`, and `spikewidgets`.\n",
    "\n",
    "For this analysis, we will be using a real dataset recorded from CA1 region in the hippocampus (recording from [CINPLA](https://www.mn.uio.no/ibv/english/research/sections/fyscell/cinpla/)). We will show how to:\n",
    "\n",
    "- load the data with spikeextractors package\n",
    "- load a probe file\n",
    "- preprocess the signals\n",
    "- run a popular spike sorting algorithm with different parameters\n",
    "- curate the spike sorting output using 1) quality metrics (automatic) - 2) [Phy](https://github.com/cortex-lab/phy) \n",
    "(manual) - 3) consensus-based\n",
    "- save the results to NWB!\n",
    "\n",
    "\n",
    "We recommend creating a new `spiketutorial` conda environment using:\n",
    "\n",
    "`conda env create -f environment.yml`\n",
    "\n",
    "In addition, for the conda environment, you need to install [Phy](https://github.com/cortex-lab/phy) for the manual curation step.\n",
    "\n",
    "`pip install phy --pre --upgrade`\n",
    "\n",
    "\n",
    "Alternatively, you can install the requirements you can use the `requirements.txt` in this directory by running the command:\n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "(in this case Phy should be automatically installed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the recording\n",
    "\n",
    "First, we need to download the recording. Feel free to use your own recordings as well later on. \n",
    "From this Zenodo [link](https://doi.org/10.5281/zenodo.3825284), you can download the dataset mentioned above (`open-ephys-dataset.zip`). Move the dataset in the current folder and unzip it.\n",
    "The recording was performed with the mircodrives with 4 tetrodes each (in total 32 channels).\n",
    "\n",
    "\n",
    "### Importing the modules\n",
    "\n",
    "Let's now import the `spikeinterface` modules that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface\n",
    "import spikeinterface.extractors as se \n",
    "import spikeinterface.toolkit as st\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.widgets as sw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading recording and probe information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Open-Ephys: reading settings...\n",
      "Decoding data from  binary  format\n",
      "Reading oebin file\n"
     ]
    }
   ],
   "source": [
    "recording_folder = '../../../spike_data/open-ephys-dataset/open-ephys-dataset/'\n",
    "recording = se.OpenEphysRecordingExtractor(recording_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[spikeextractors.extractors.mdaextractors.mdaextractors.MdaRecordingExtractor,\n",
       " spikeextractors.extractors.mearecextractors.mearecextractors.MEArecRecordingExtractor,\n",
       " spikeextractors.extractors.biocamrecordingextractor.biocamrecordingextractor.BiocamRecordingExtractor,\n",
       " spikeextractors.extractors.exdirextractors.exdirextractors.ExdirRecordingExtractor,\n",
       " spikeextractors.extractors.openephysextractors.openephysextractors.OpenEphysRecordingExtractor,\n",
       " spikeextractors.extractors.intanrecordingextractor.intanrecordingextractor.IntanRecordingExtractor,\n",
       " spikeextractors.extractors.bindatrecordingextractor.bindatrecordingextractor.BinDatRecordingExtractor,\n",
       " spikeextractors.extractors.klustaextractors.klustaextractors.KlustaRecordingExtractor,\n",
       " spikeextractors.extractors.kilosortextractors.kilosortextractors.KiloSortRecordingExtractor,\n",
       " spikeextractors.extractors.spykingcircusextractors.spykingcircusextractors.SpykingCircusRecordingExtractor,\n",
       " spikeextractors.extractors.spikeglxrecordingextractor.spikeglxrecordingextractor.SpikeGLXRecordingExtractor,\n",
       " spikeextractors.extractors.phyextractors.phyextractors.PhyRecordingExtractor,\n",
       " spikeextractors.extractors.maxoneextractors.maxoneextractors.MaxOneRecordingExtractor,\n",
       " spikeextractors.extractors.mea1kextractors.mea1kextractors.Mea1kRecordingExtractor,\n",
       " spikeextractors.extractors.mcsh5recordingextractor.mcsh5recordingextractor.MCSH5RecordingExtractor,\n",
       " spikeextractors.extractors.shybridextractors.shybridextractors.SHYBRIDRecordingExtractor,\n",
       " spikeextractors.extractors.nixioextractors.nixioextractors.NIXIORecordingExtractor,\n",
       " spikeextractors.extractors.neuroscopeextractors.neuroscopeextractors.NeuroscopeRecordingExtractor,\n",
       " spikeextractors.extractors.neuroscopeextractors.neuroscopeextractors.NeuroscopeMultiRecordingTimeExtractor,\n",
       " spikeextractors.extractors.cedextractors.cedrecordingextractor.CEDRecordingExtractor,\n",
       " spikeextractors.extractors.neoextractors.plexonextractor.PlexonRecordingExtractor,\n",
       " spikeextractors.extractors.neoextractors.neuralynxextractor.NeuralynxRecordingExtractor,\n",
       " spikeextractors.extractors.neoextractors.blackrockextractor.BlackrockRecordingExtractor,\n",
       " spikeextractors.extractors.neoextractors.mcsrawrecordingextractor.MCSRawRecordingExtractor]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.recording_extractor_full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[spikeextractors.extractors.mdaextractors.mdaextractors.MdaRecordingExtractor,\n",
       " spikeextractors.extractors.biocamrecordingextractor.biocamrecordingextractor.BiocamRecordingExtractor,\n",
       " spikeextractors.extractors.openephysextractors.openephysextractors.OpenEphysRecordingExtractor,\n",
       " spikeextractors.extractors.bindatrecordingextractor.bindatrecordingextractor.BinDatRecordingExtractor,\n",
       " spikeextractors.extractors.klustaextractors.klustaextractors.KlustaRecordingExtractor,\n",
       " spikeextractors.extractors.kilosortextractors.kilosortextractors.KiloSortRecordingExtractor,\n",
       " spikeextractors.extractors.spykingcircusextractors.spykingcircusextractors.SpykingCircusRecordingExtractor,\n",
       " spikeextractors.extractors.spikeglxrecordingextractor.spikeglxrecordingextractor.SpikeGLXRecordingExtractor,\n",
       " spikeextractors.extractors.phyextractors.phyextractors.PhyRecordingExtractor,\n",
       " spikeextractors.extractors.maxoneextractors.maxoneextractors.MaxOneRecordingExtractor,\n",
       " spikeextractors.extractors.mea1kextractors.mea1kextractors.Mea1kRecordingExtractor,\n",
       " spikeextractors.extractors.mcsh5recordingextractor.mcsh5recordingextractor.MCSH5RecordingExtractor,\n",
       " spikeextractors.extractors.neoextractors.mcsrawrecordingextractor.MCSRawRecordingExtractor]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.installed_recording_extractor_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `RecordingExtractor` object extracts information about channel ids, channel locations (if present), the sampling frequency of the recording, and the extracellular traces (when prompted). The `OpenEphysRecording` is designed specifically for open-ephys datasets.\n",
    "\n",
    "Here we load information from the recording using the built-in functions from the RecordingExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spikeextractors.extractors.openephysextractors.openephysextractors.OpenEphysRecordingExtractor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel ids: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "Sampling frequency: 30000.0\n",
      "Number of channels: 32\n"
     ]
    }
   ],
   "source": [
    "channel_ids = recording.get_channel_ids()\n",
    "fs = recording.get_sampling_frequency()\n",
    "num_chan = recording.get_num_channels()\n",
    "\n",
    "print(f'Channel ids: {channel_ids}')\n",
    "print(f'Sampling frequency: {fs}')\n",
    "print(f'Number of channels: {num_chan}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_traces()` function returns a NxT numpy array where N is the number of channel ids passed in (all channel ids are passed in by default) and T is the number of frames (determined by start_frame and end_frame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__abstractmethods__\n",
      "__class__\n",
      "__del__\n",
      "__delattr__\n",
      "__dict__\n",
      "__dir__\n",
      "__doc__\n",
      "__eq__\n",
      "__format__\n",
      "__ge__\n",
      "__getattribute__\n",
      "__gt__\n",
      "__hash__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__le__\n",
      "__lt__\n",
      "__module__\n",
      "__ne__\n",
      "__new__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__setattr__\n",
      "__sizeof__\n",
      "__slots__\n",
      "__str__\n",
      "__subclasshook__\n",
      "__weakref__\n",
      "_abc_impl\n",
      "_cast_start_end_frame\n",
      "_default_filename\n",
      "_dtype\n",
      "_epochs\n",
      "_features\n",
      "_get_file_path\n",
      "_key_properties\n",
      "_kwargs\n",
      "_memmap_files\n",
      "_properties\n",
      "_recording\n",
      "_recording_file\n",
      "_tmp_folder\n",
      "add_epoch\n",
      "allocate_array\n",
      "check_if_dumpable\n",
      "clear_channel_property\n",
      "clear_channels_property\n",
      "copy_channel_properties\n",
      "copy_epochs\n",
      "del_memmap_file\n",
      "dump_to_dict\n",
      "dump_to_json\n",
      "dump_to_pickle\n",
      "extractor_name\n",
      "frame_to_time\n",
      "get_channel_gains\n",
      "get_channel_groups\n",
      "get_channel_ids\n",
      "get_channel_locations\n",
      "get_channel_property\n",
      "get_channel_property_names\n",
      "get_dtype\n",
      "get_epoch\n",
      "get_epoch_info\n",
      "get_epoch_names\n",
      "get_num_channels\n",
      "get_num_frames\n",
      "get_sampling_frequency\n",
      "get_shared_channel_property_names\n",
      "get_snippets\n",
      "get_sub_extractors_by_property\n",
      "get_tmp_folder\n",
      "get_traces\n",
      "get_ttl_events\n",
      "has_default_locations\n",
      "id\n",
      "installation_mesg\n",
      "installed\n",
      "is_dumpable\n",
      "is_filtered\n",
      "is_writable\n",
      "load_extractor_from_dict\n",
      "load_extractor_from_json\n",
      "load_extractor_from_pickle\n",
      "load_probe_file\n",
      "make_serialized_dict\n",
      "mode\n",
      "remove_epoch\n",
      "save_to_probe_file\n",
      "set_channel_gains\n",
      "set_channel_groups\n",
      "set_channel_locations\n",
      "set_channel_property\n",
      "set_tmp_folder\n",
      "time_to_frame\n",
      "write_recording\n",
      "write_to_binary_dat_format\n",
      "write_to_h5_dataset_format\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(l) for l in dir(recording)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AnalogSignal' object has no attribute 'gain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-23486cbc8b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrace_snippet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecording\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/d/spikeinterface/spiketutorials/NWB_Developer_Breakout_Session_Sep2020/venv/lib/python3.8/site-packages/spikeextractors/extraction_tools.py\u001b[0m in \u001b[0;36mcorrected_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# pass recording as arg and rest as kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0mget_traces_correct_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_traces_correct_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/spikeinterface/spiketutorials/NWB_Developer_Breakout_Session_Sep2020/venv/lib/python3.8/site-packages/spikeextractors/extractors/openephysextractors/openephysextractors.py\u001b[0m in \u001b[0;36mget_traces\u001b[0;34m(self, channel_ids, start_frame, end_frame)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'float'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalog_signals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannel_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_frame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_frame\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalog_signals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcheck_get_ttl_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AnalogSignal' object has no attribute 'gain'"
     ]
    }
   ],
   "source": [
    "trace_snippet = recording.get_traces(start_frame=int(fs*0), end_frame=int(fs*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Traces shape:', trace_snippet.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `spikewidgets` module includes several convenient plotting functions that can be used to explore the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w_ts = sw.plot_timeseries(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sp = sw.plot_spectrum(recording, channels=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the spikes mainly appear separately on different tetrodes. Each tetrode belongs to a different `group`. We can load the `group` information in two ways:\n",
    "\n",
    "- using the `set_channel_groups` in your RecordingExtractor (manually loading group information)\n",
    "- loading a probe file using the `load_probe_file` from RecordingExtractor (automatically loading group information)\n",
    "\n",
    "Let's use the second option. Probe files (`.prb`) also enable users to change the channel map (reorder the channels) and add channel grouping properties and locations. In this case, our probe file will order the channels in reverse and split them in 4 groups, representing the 4 tetrodes. We'll also add locations to separate the different tetrodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only works on linux and mac. For windows, open the file using a text editor\n",
    "!cat tetrode_32.prb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_prb = recording.load_probe_file('tetrode_32.prb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original channels: {recording.get_channel_ids()}')\n",
    "print(f'Channels after loading the probe file: {recording_prb.get_channel_ids()}')\n",
    "print(f'Channel groups after loading the probe file: {recording_prb.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_elec = sw.plot_electrode_geometry(recording_prb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties (and features)\n",
    "\n",
    "For now we have seen that the `RecordingEctractor` can have `group` and `location` *properies*. These are very special properties that can be very important for spike sorting. Anything related to a channel can be saved as a property.\n",
    "\n",
    "Similarly, for `SortingExtractor` objects, anything related to a unit can be stored as a property. In addition, for `SortingExtractor` objects we can also store anything related to spikes as *features* (e.g. waveforms, as we'll see later).\n",
    "\n",
    "We can check which properties are in the estractor as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recording.get_shared_channel_property_names())\n",
    "print(recording_prb.get_shared_channel_property_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a new property! The first 16 channels are in the left hemisphere, the second 16 are in the right one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in recording_prb.get_channel_ids():\n",
    "    if ch < 16:\n",
    "        recording_prb.set_channel_property(ch, property_name='hemisphere', value='left')\n",
    "    else:\n",
    "        recording_prb.set_channel_property(ch, property_name='hemisphere', value='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recording_prb.get_shared_channel_property_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing recordings\n",
    "\n",
    "\n",
    "Now that the probe information is loaded we can do some preprocessing using `spiketoolkit`.\n",
    "\n",
    "We can filter the recordings, rereference the signals to remove noise, discard noisy channels, whiten the data, remove stimulation artifacts, etc. (more info [here](https://spiketoolkit.readthedocs.io/en/latest/preprocessing_example.html)).\n",
    "\n",
    "For this notebook, let's filter the recordings, remove a noisy channel, and apply common median reference (CMR). All preprocessing modules return new `RecordingExtractor` objects that apply the underlying preprocessing function. This allows users to access the preprocessed data in the same way as the raw data.\n",
    "\n",
    "Below, we bandpass filter the recording, remove channel 5, and apply common median reference to the original recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recording_f = st.preprocessing.bandpass_filter(recording_prb, freq_min=300, freq_max=6000)\n",
    "\n",
    "w = sw.plot_timeseries(recording_f, color_groups=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first drive is quite active, while the second one is not. For sake of time, we can just focus on the first drive (channels 0-15). We can easily select these channels and get a new extractor using the `SubRecordingExtractor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_1 = se.SubRecordingExtractor(recording_f, channel_ids=range(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Sub channels: {recording_1.get_channel_ids()}')\n",
    "print(f'Channel groups after SubRecordingExtractor: {recording_1.get_channel_groups()}')\n",
    "w = sw.plot_timeseries(recording_1, color_groups=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can notice from the first and second plot, channel 2 seems to be a bit noisy. We can remove it using the `remove_bad_channels` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_rm_noise = st.preprocessing.remove_bad_channels(recording_1, bad_channel_ids=[2])\n",
    "print(f'Channel ids after removing bad channel: {recording_rm_noise.get_channel_ids()}')\n",
    "print(f'Channel groups after removing bad channel: {recording_rm_noise.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cmr = st.preprocessing.common_reference(recording_rm_noise, reference='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the traces after removing the bad channel and applying CMR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_timeseries(recording_cmr, color_groups=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Channel ids for CMR recordings: {recording_cmr.get_channel_ids()}')\n",
    "print(f'Channel groups for CMR recordings: {recording_cmr.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are going to spike sort the data, let's first cut out a 2-minute recording, to speed up computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = recording_cmr.get_sampling_frequency()\n",
    "recording_sub = se.SubRecordingExtractor(recording_cmr, start_frame=200*fs, end_frame=320*fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching \n",
    "\n",
    "All operations in SpikeInterface are *lazy*, meaning that they are not performed if not needed. This is why the creation of our filter recording was almost instantaneous. However, to speed up further processing, we might want to **cache** it to a file and perform those operations (eg. filters, CMR, etc.) at once. This is particularly important if we are going to extract waveforms, templates, pca scores, or in general *post-process* the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cache = se.CacheRecordingExtractor(recording_sub) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cached recording has all the previously loaded information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Cached channels: {recording_cache.get_channel_ids()}')\n",
    "print(f'Cached channels ids: {recording_cache.get_channel_ids()}')\n",
    "print(f'Channel groups after caching: {recording_cache.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, this convenient function is retrieving all the traces (in chunks, to save up some memory), applying the preprocessing steps, and dumping them to a binary temporary file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cache.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all extractors (including sorting extractors), have a temporary folder associated with it, that enables SpikeInterface to cache several data (including waveforms) and be gentle on RAM usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cache.get_tmp_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temporary files in the tmp folder, are *temporary*, and they will be deleted when the Python session is closed (or the object destroyed). To prevent this, we can simply move the binary file to a custom location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cache.move_to('filtered_data.dat') \n",
    "print(recording_cache.filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could have passed the `save_path` argument to the `se.CacheRecordingExtractor` directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now closed the Python session, we would have a nice `.dat` file, but no information on how to open it! \n",
    "In order to save the state of an extractor, we can use the **dumping** mechanism.\n",
    "Each extractor can be converted to a dictionary, which holds the path to the data file and all relevant information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cache.dump_to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now dump our extractor object, so it can be loaded in a future session. We can dump either to `.json` or to `.pkl`. Dumping to pickle also allow us to store properties (other than group and locations) and features (for `SortingExtractor` objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cache.dump_to_pickle('recording.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another session, we can pick up from where we left by loading the extractor from the pickle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_loaded = se.load_extractor_from_pickle('recording.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_timeseries(recording_loaded, color_groups=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check that the traces are exactly the same as the `recording_sub` that we dumped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_timeseries(recording_sub, color_groups=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: the same caching/dumping mechanisms are available also for all SortingExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike sorting\n",
    "\n",
    "We can now run spike sorting on the above recording. We will use `klusta` and `ironclust` for this demonstration, to show how easy SpikeInterface makes it to interchengably run different sorters :)\n",
    "\n",
    "Let's first check the installed sorters in spiketoolkit to see if klusta is available. Then we can check the `klusta` default parameters.\n",
    "We will sort the bandpass cached filtered recording the `recording_cache` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.installed_sorters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the parameters associated to any sorter with the `get_default_params()` function from the `spikesorters` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.get_default_params('klusta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.get_params_description('klusta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.run_sorter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.run_klusta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the `adjacency_radius` to 50 microns as electrodes belonging to the same tetrode are within this distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run spike sorting on entire recording\n",
    "sorting_KL_all = ss.run_klusta(recording_cache, output_folder='results_all_klusta', adjacency_radius=50, verbose=True)\n",
    "print('Found', len(sorting_KL_all.get_unit_ids()), 'units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpikeInterface ensures full provenance of the spike sorting pipeline. Upon running a spike sorter, a `spikeinterface_params.json` file is saved in the `output_folder`. This contains a `.json` version of the recording and all the input parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike sorting by group\n",
    "\n",
    "Since we have 4 tetrodes and we know that they are physically apart, we would like to sort them separately.\n",
    "\n",
    "Here is how it's done in SpikeInterface:\n",
    "\n",
    "![](sort_by_group.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spike sorting by group \n",
    "sorting_KL = ss.run_klusta(recording_cache, adjacency_radius=50, \n",
    "                                      output_folder='results_split_klusta', \n",
    "                                      grouping_property='group', parallel=True)\n",
    "print(f'Klusta found {len(sorting_KL.get_unit_ids())} units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sorting_KL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_KL.sortings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing IronClust (requires MATLAB)\n",
    "\n",
    "For MATLAB-based sorters, all you need to do is cloning the sorter repo and point it to SpikeInterface:\n",
    "\n",
    "Let's clone ironclust in the current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/flatironinstitute/ironclust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have to tell the IronClustSorter class where is the ironclust repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.IronClustSorter.set_ironclust_path('./ironclust')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can also set a global environment variable called `IRONCLUST_PATH`. In that case we don't need to set the path in each session because the sorter class looks for this environment variable.\n",
    "\n",
    "Now ironclust should be installed and we can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.IronClustSorter.ironclust_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $IRONCLUST_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.installed_sorters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spike sorting by group\n",
    "sorting_IC = ss.run_ironclust(recording_cache, \n",
    "                              output_folder='results_split_ic', \n",
    "                              grouping_property='group', parallel=True, verbose=True)\n",
    "print(f'IronClust found {len(sorting_IC.get_unit_ids())} units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spike sorting returns a `SortingExtractor` object. Let's see some of its functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Klusta unit ids: {sorting_KL.get_unit_ids()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Spike train of a unit: {sorting_KL.get_unit_spike_train(13)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `spikewidgets` functions to quickly visualize some unit features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rs = sw.plot_rasters(sorting_IC, trange=[0,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform some automatic curation by thresholding low snr units on the split sorting result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a spike sorting output from a spike sorting folder\n",
    "\n",
    "If a spike sorter has been run, you can reload the output as a `SortingExtractor` using the corresponding `spikeextractors` class. Note that if sorting by group/property, single groups must be loaded separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_KL_0 = se.KlustaSortingExtractor(\"results_split_klusta/0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Klusta unit ids group 0: {sorting_KL_0.get_unit_ids()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postptocessing\n",
    "\n",
    "The `postprocessing` submodule of `spiketoolkit` allow us to extract information from the combination of the recording and sorting extractors. For example, we can extract waveforms, templates, maximum channels and pca scores. In addition, we can also compute waveform features that could be used for further processing, e.g. classyfing excitatory-inhibitory neurons.\n",
    "\n",
    "To extract the waveforms, we can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = st.postprocessing.get_unit_waveforms(recording_cache, sorting_IC, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can get templates, maximum channels, and pca scores. \n",
    "Whem these are computed, they are automatically stored in the `SortingExtractor` object, so that they don't need to be recomputed. \n",
    "\n",
    "Each waveform is associated with a specific spike, so they are saved as spike *features*:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that 300 waveforms were extracted from the spike train of the first unit. However, it has more spikes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorting_IC.get_unit_spike_train(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be convenient to only compute a subset of waveforms to speed up the calculation. The `waveform_idxs` property contains the spike indexes associated with the waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_IC.get_shared_unit_spike_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorting_IC.get_unit_spike_features(0, 'waveforms_idxs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since waveforms are already computed, the next time we (or another function - e.g. `get_unit_templates()`) call it it will just return the stored waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = st.postprocessing.get_unit_waveforms(recording_cache, sorting_IC, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lighthing fast! \n",
    "\n",
    "If we want to recompute the waveforms, for example because we want to extract the waveforms divided by group, we can use the `recompute_info` argument (available for all `postprocessing`, `validation`, and `curation` functions):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where are waveforms stored? We have seen above that each `Extractor` object has a tmp folder associated. Waveforms (and other features, e.g. pca scores) are stored in this folder as binary raw files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_folder = sorting_IC.get_tmp_folder()\n",
    "print(tmp_folder)\n",
    "print([(p.name) for p in tmp_folder.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms_group = st.postprocessing.get_unit_waveforms(recording_cache, sorting_IC, max_spikes_per_unit=None, \n",
    "                                                       grouping_property='group', recompute_info=True,\n",
    "                                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_IC.get_shared_unit_property_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wf in waveforms_group:\n",
    "    print(wf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `spikewidgets` to quickly inspect the spike sorting output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_wf = sw.plot_unit_templates(sorting=sorting_IC, recording=recording_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_acc = sw.plot_autocorrelograms(sorting_IC, unit_ids=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute extracellular features\n",
    "\n",
    "Extracellular features, such as peak to valley duration or full-width half maximum, are important to classify neurons into putative classes (excitatory - inhibitory). The `postprocessing` module of `spiketoolkit` allows one to compute several of these features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.get_template_features_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = st.postprocessing.compute_unit_template_features(recording_cache, sorting_IC, as_dataframe=True, \n",
    "                                                            upsampling_factor=10)\n",
    "display(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about these waveform features, we refer to this [documentation](https://github.com/AllenInstitute/ecephys_spike_sorting/tree/master/ecephys_spike_sorting/modules/mean_waveforms) from the Allen Institute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "The `spiketoolkit` package also provides several functions to compute qualitity metrics about the spike sorting results through the `validation` module.\n",
    "\n",
    "Let's see what metrics are available:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.validation.get_quality_metrics_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either compute one metric at a time, or compute a subset of metrics using the `compute_quality_metrics` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = recording.get_num_frames()\n",
    "isi_violations = st.validation.compute_isi_violations(sorting_IC, duration_in_frames=duration)\n",
    "print('ISI violations:', isi_violations)\n",
    "\n",
    "snrs = st.validation.compute_snrs(sorting_IC, recording_cache)\n",
    "print('SNRs:', snrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_metrics = st.validation.compute_quality_metrics(sorting_IC, recording_cache, \n",
    "                                                        metric_names=['firing_rate', 'isi_violation', 'snr'], \n",
    "                                                        as_dataframe=True)\n",
    "display(quality_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about these waveform features, we refer to this [documentation](https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_quality_metrics.html) from the Allen Institute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Manual curation using Phy\n",
    "\n",
    "To perform manual curation we will export the data to [Phy](https://github.com/cortex-lab/phy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.export_to_phy(recording_cache, \n",
    "                                sorting_IC, output_folder='phy_IC',\n",
    "                                grouping_property='group', verbose=True, recompute_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui phy_IC/params.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After curating the results we can reload it using the `PhySortingExtractor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_IC_phy_curated = se.PhySortingExtractor('phy_IC/', exclude_cluster_groups=['noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sorting_IC_phy_curated.get_unit_ids()))\n",
    "print(f\"Unit ids after manual curation: {sorting_IC_phy_curated.get_unit_ids()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same for the klusta output.\n",
    "# st.postprocessing.export_to_phy(recording_cache, \n",
    "#                                 sorting_KL, output_folder='phy_KL',\n",
    "#                                 grouping_property='group', verbose=True, recompute_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-display\n",
    "# !phy template-gui phy_KL/params.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Automatic curation based on quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_thresh = 5\n",
    "isi_viol_thresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_auto = st.curation.threshold_isi_violations(sorting_KL, isi_viol_thresh, 'greater', duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorting_auto.get_unit_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_auto = st.curation.threshold_snrs(sorting_auto, recording_cache, snr_thresh, 'less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorting_auto.get_unit_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Consensus-based curation \n",
    "\n",
    "Can we combine the output of multiple sorters to curate the spike sorting output?\n",
    "\n",
    "To answer this question we can use the `comparison` module.\n",
    "We first compare and match the output spike trains of the different sorters, and we can then extract a new `SortingExtractor` with only the units in agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmp = sc.compare_multiple_sorters([sorting_KL, sorting_IC], ['KL', 'IC'], spiketrain_mode='union',\n",
    "                                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_multicomp_agreement(mcmp)\n",
    "w = sw.plot_multicomp_agreement_by_sorter(mcmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_sorting = mcmp.get_agreement_sorting(minimum_agreement_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_sorting.get_unit_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_manual_agr = sc.compare_sorter_to_ground_truth(sorting_IC_phy_curated, agreement_sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_agr = sw.plot_agreement_matrix(cmp_manual_agr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.export_to_phy(recording_cache, \n",
    "                                agreement_sorting, output_folder='phy_AGR',\n",
    "                                grouping_property='group', verbose=True, recompute_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui phy_AGR/params.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to / load from NWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {'Ecephys': {'Device': [{'name': 'open-ephys',\n",
    "                                    'description': 'Open Ephys acquisition board'}]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "se.NwbRecordingExtractor.write_recording(recording_cache, 'si_tutorial.nwb', metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "se.NwbSortingExtractor.write_sorting(sorting_IC, 'si_tutorial.nwb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_nwb = se.NwbRecordingExtractor('si_tutorial.nwb')\n",
    "sorting_nwb = se.NwbSortingExtractor('si_tutorial.nwb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
